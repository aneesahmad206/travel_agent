"""
This type stub file was generated by pyright.
"""

import pandas
from pathlib import Path
from typing import Any, AsyncGenerator, Callable, Generator, Literal, TYPE_CHECKING
from ibm_watsonx_ai.wml_resource import WMLResource
from ibm_watsonx_ai import APIClient
from ibm_watsonx_ai.lifecycle import SpecStates

if TYPE_CHECKING:
    ...
_OAPI = ...
class AIServices(WMLResource):
    """Store and manage an AI service."""
    def __init__(self, client: APIClient) -> None:
        ...
    
    def store(self, ai_service: str | Path | Callable, meta_props: dict[str, Any]) -> dict:
        """Create an AI service asset.

        .. note::

            Supported for IBM watsonx.ai for IBM Cloud and IBM watsonx.ai software with IBM Cloud Pak® for Data (version 5.1.1 and later).

        You can use one of the following as an `ai_service`:
            - filepath to gz file
            - generator function that takes no argument or arguments that all have primitive python default values, and returns a `generate` function.

        :param ai_service: path to a file with an archived AI service function's content or a generator function (as described above)
        :type ai_service: str | Path | Callable

        :param meta_props: metadata for storing an AI service asset. To see available meta names
            use ``client._ai_services.ConfigurationMetaNames.show()`` or direct to :class:`~metanames.AIServiceMetaNames` class.
        :type meta_props: dict

        :return: metadata of the stored AI service
        :rtype: dict

        **Examples:**

        The most simple use of an AI service is:

        .. code-block:: python

            documentation_request = {
                "application/json": {
                    "$schema": "http://json-schema.org/draft-07/schema#",
                    "type": "object",
                    "properties": {
                        "query": {"type": "string"},
                        "parameters": {
                            "properties": {
                                "max_new_tokens": {"type": "integer"},
                                "top_p": {"type": "number"},
                            },
                            "required": ["max_new_tokens", "top_p"],
                        },
                    },
                    "required": ["query"],
                }
            }

            documentation_response = {
                "application/json": {
                    "$schema": "http://json-schema.org/draft-07/schema#",
                    "type": "object",
                    "properties": {
                        "query": {"type": "string"},
                        "result": {"type": "string"},
                    },
                    "required": ["query", "result"],
                }
            }

            meta_props = {
                client._ai_services.ConfigurationMetaNames.NAME: "AI service example",
                client._ai_services.ConfigurationMetaNames.DESCRIPTION: "This is AI service function",
                client._ai_services.ConfigurationMetaNames.SOFTWARE_SPEC_ID: "53dc4cf1-252f-424b-b52d-5cdd9814987f",
                client._ai_services.ConfigurationMetaNames.DOCUMENTATION_REQUEST: documentation_request,
                client._ai_services.ConfigurationMetaNames.DOCUMENTATION_RESPONSE: documentation_response,
            }


            def deployable_ai_service(context, params={"k1": "v1"}, **kwargs):
                # imports
                from ibm_watsonx_ai import Credentials
                from ibm_watsonx_ai.foundation_models import ModelInference

                task_token = context.generate_token()

                outer_context = context
                url = "https://us-south.ml.cloud.ibm.com"
                project_id = "53dc4cf1-252f-424b-b52d-5cdd9814987f"

                def generate(context):
                    task_token = outer_context.generate_token()
                    payload = context.get_json()

                    model = ModelInference(
                        model_id="google/flan-t5-xl",
                        credentials=Credentials(url=url, token=task_token),
                        project_id=project_id,
                    )

                    response = model.generate_text(payload["query"])
                    response_body = {"query": payload["query"], "result": response}

                    return {"body": response_body}

                return generate


            stored_ai_service_details = client._ai_services.store(
                deployable_ai_service, meta_props
            )

        """
        ...
    
    async def astore(self, ai_service: str | Path | Callable, meta_props: dict[str, Any]) -> dict:
        """Create an AI service asset asynchronously.

        .. note::

            Supported for IBM watsonx.ai for IBM Cloud and IBM watsonx.ai software with IBM Cloud Pak® for Data (version 5.1.1 and later).

        You can use one of the following as an `ai_service`:
            - filepath to gz file
            - generator function that takes no argument or arguments that all have primitive python default values, and returns a `generate` function.

        :param ai_service: path to a file with an archived AI service function's content or a generator function (as described above)
        :type ai_service: str | Path | Callable

        :param meta_props: metadata for storing an AI service asset. To see available meta names
            use ``client._ai_services.ConfigurationMetaNames.show()`` or direct to :class:`~metanames.AIServiceMetaNames` class.
        :type meta_props: dict

        :return: metadata of the stored AI service
        :rtype: dict

        **Examples:**

        The most simple use of an AI service is:

        .. code-block:: python

            documentation_request = {
                "application/json": {
                    "$schema": "http://json-schema.org/draft-07/schema#",
                    "type": "object",
                    "properties": {
                        "query": {"type": "string"},
                        "parameters": {
                            "properties": {
                                "max_new_tokens": {"type": "integer"},
                                "top_p": {"type": "number"},
                            },
                            "required": ["max_new_tokens", "top_p"],
                        },
                    },
                    "required": ["query"],
                }
            }

            documentation_response = {
                "application/json": {
                    "$schema": "http://json-schema.org/draft-07/schema#",
                    "type": "object",
                    "properties": {
                        "query": {"type": "string"},
                        "result": {"type": "string"},
                    },
                    "required": ["query", "result"],
                }
            }

            meta_props = {
                client._ai_services.ConfigurationMetaNames.NAME: "AI service example",
                client._ai_services.ConfigurationMetaNames.DESCRIPTION: "This is AI service function",
                client._ai_services.ConfigurationMetaNames.SOFTWARE_SPEC_ID: "53dc4cf1-252f-424b-b52d-5cdd9814987f",
                client._ai_services.ConfigurationMetaNames.DOCUMENTATION_REQUEST: documentation_request,
                client._ai_services.ConfigurationMetaNames.DOCUMENTATION_RESPONSE: documentation_response,
            }


            def deployable_ai_service(context, params={"k1": "v1"}, **kwargs):
                # imports
                from ibm_watsonx_ai import Credentials
                from ibm_watsonx_ai.foundation_models import ModelInference

                task_token = context.generate_token()

                outer_context = context
                url = "https://us-south.ml.cloud.ibm.com"
                project_id = "53dc4cf1-252f-424b-b52d-5cdd9814987f"

                def generate(context):
                    task_token = outer_context.generate_token()
                    payload = context.get_json()

                    model = ModelInference(
                        model_id="google/flan-t5-xl",
                        credentials=Credentials(url=url, token=task_token),
                        project_id=project_id,
                    )

                    response = model.generate_text(payload["query"])
                    response_body = {"query": payload["query"], "result": response}

                    return {"body": response_body}

                return generate


            stored_ai_service_details = await client._ai_services.astore(
                deployable_ai_service, meta_props
            )

        """
        ...
    
    def update(self, ai_service_id: str, changes: dict, update_ai_service: str | Path | Callable | None = ...) -> dict:
        """Updates existing AI service asset metadata.

        :param ai_service_id: ID of AI service to be updated
        :type ai_service_id: str

        :param changes: elements that will be changed, where keys are ConfigurationMetaNames
        :type changes: dict

        :param update_ai_service: path to the file with an archived AI service function's content or function that will be changed for a specific ai_service_id
        :type update_ai_service: str | Path | Callable, optional

        **Example:**

        .. code-block:: python

            metadata = {
                client._ai_services.ConfigurationMetaNames.NAME: "updated_ai_service"
            }

            ai_service_details = client._ai_services.update(
                ai_service_id, changes=metadata
            )

        """
        ...
    
    async def aupdate(self, ai_service_id: str, changes: dict, update_ai_service: str | Path | Callable | None = ...) -> dict:
        """Updates existing AI service asset metadata asynchronously.

        :param ai_service_id: ID of AI service to be updated
        :type ai_service_id: str

        :param changes: elements that will be changed, where keys are ConfigurationMetaNames
        :type changes: dict

        :param update_ai_service: path to the file with an archived AI service function's content or function that will be changed for a specific ai_service_id
        :type update_ai_service: str | Path | Callable, optional

        **Example:**

        .. code-block:: python

            metadata = {
                client._ai_services.ConfigurationMetaNames.NAME: "updated_ai_service"
            }

            ai_service_details = await client._ai_services.aupdate(
                ai_service_id, changes=metadata
            )

        """
        ...
    
    def download(self, ai_service_id: str, filename: str | Path = ..., rev_id: str | None = ...) -> str:
        """Download an AI service’s content from a watsonx.ai repository to a local file.

        :param ai_service_id: stored AI service ID
        :type ai_service_id: str

        :param filename: name of the local file to be created, example: ai_service_content.py.gz
        :type filename: str | Path, optional

        :param rev_id: revision ID
        :type rev_id: str, optional

        :return: path to the downloaded AI service content
        :rtype: str

        **Example:**

        .. code-block:: python

            client._ai_services.download(ai_service_id, "my_ai_service.py.gz")

        """
        ...
    
    async def adownload(self, ai_service_id: str, filename: str | Path = ..., rev_id: str | None = ...) -> str:
        """Download an AI service’s content from a watsonx.ai repository to a local file asynchronously.

        :param ai_service_id: stored AI service ID
        :type ai_service_id: str

        :param filename: name of the local file to be created, example: ai_service_content.py.gz
        :type filename: str | Path, optional

        :param rev_id: revision ID
        :type rev_id: str, optional

        :return: path to the downloaded AI service content
        :rtype: str

        **Example:**

        .. code-block:: python

            await client._ai_services.adownload(
                ai_service_id, "my_ai_service.py.gz"
            )

        """
        ...
    
    def delete(self, ai_service_id: str, force: bool = ...) -> Literal["SUCCESS"]:
        """Delete a stored AI service asset.

        :param ai_service_id: stored AI service ID
        :type ai_service_id: str

        :param force: if True, the delete operation will proceed even when the AI service deployment exists, defaults to False
        :type force: bool, optional

        :return: status "SUCCESS" if deletion is successful
        :rtype: Literal["SUCCESS"]
        :raises: ApiRequestFailure if deletion failed

        **Example:**

        .. code-block:: python

            client._ai_services.delete(ai_service_id)
        """
        ...
    
    async def adelete(self, ai_service_id: str, force: bool = ...) -> Literal["SUCCESS"]:
        """Delete a stored AI service asset asynchronously.

        :param ai_service_id: stored AI service ID
        :type ai_service_id: str

        :param force: if True, the delete operation will proceed even when the AI service deployment exists, defaults to False
        :type force: bool, optional

        :return: status "SUCCESS" if deletion is successful
        :rtype: Literal["SUCCESS"]
        :raises: ApiRequestFailure if deletion failed

        **Example:**

        .. code-block:: python

            await client._ai_services.adelete(ai_service_id)
        """
        ...
    
    def get_details(self, ai_service_id: str | None = ..., limit: int | None = ..., asynchronous: bool = ..., get_all: bool = ..., spec_state: SpecStates | None = ..., ai_service_name: str | None = ...) -> dict | Generator:
        """Get the metadata of AI service(s). If neither AI service ID nor AI service name is specified,
        all AI service metadata is returned.
        If only AI service name is specified, metadata of AI services with the name is returned (if any).

        :param ai_service_id: ID of the AI service
        :type ai_service_id: str, optional

        :param limit: limit number of fetched records
        :type limit: int | None, optional

        :param asynchronous: if `True`, it will work as a generator, defaults to False
        :type asynchronous: bool, optional

        :param get_all: if `True`, it will get all entries in 'limited' chunks, defaults to False
        :type get_all: bool, optional

        :param spec_state: software specification state, can be used only when `ai_service_id` is None
        :type spec_state: SpecStates | None, optional

        :param ai_service_name: name of the AI service, can be used only when `ai_service_id` is None
        :type ai_service_name: str, optional

        :return: metadata of the AI service
        :rtype: dict (if ID is not None) or {"resources": [dict]} (if ID is None)

        .. note::
            In the current implementation setting, `spec_state=True` might break the set `limit` and return less records than stated in the set `limit`.

        **Examples:**

        .. code-block:: python

            ai_service_details = client._ai_services.get_details(ai_service_id)
            ai_service_details = client._ai_services.get_details(ai_service_name)
            ai_service_details = client._ai_services.get_details()
            ai_service_details = client._ai_services.get_details(limit=100)
            ai_service_details = client._ai_services.get_details(
                limit=100, get_all=True
            )
            ai_service_details = []
            for entry in client._ai_services.get_details(
                limit=100, asynchronous=True, get_all=True
            ):
                ai_service_details.extend(entry)

        """
        ...
    
    async def aget_details(self, ai_service_id: str | None = ..., limit: int | None = ..., asynchronous: bool = ..., get_all: bool = ..., spec_state: SpecStates | None = ..., ai_service_name: str | None = ...) -> dict | AsyncGenerator:
        """Get the metadata of AI service(s) asynchronously. If neither AI service ID nor AI service name is specified,
        all AI service metadata is returned.
        If only AI service name is specified, metadata of AI services with the name is returned (if any).

        :param ai_service_id: ID of the AI service
        :type ai_service_id: str, optional

        :param limit: limit number of fetched records
        :type limit: int | None, optional

        :param asynchronous: if `True`, it will work as a generator, defaults to False
        :type asynchronous: bool, optional

        :param get_all: if `True`, it will get all entries in 'limited' chunks, defaults to False
        :type get_all: bool, optional

        :param spec_state: software specification state, can be used only when `ai_service_id` is None
        :type spec_state: SpecStates | None, optional

        :param ai_service_name: name of the AI service, can be used only when `ai_service_id` is None
        :type ai_service_name: str, optional

        :return: metadata of the AI service
        :rtype: dict (if ID is not None) or {"resources": [dict]} (if ID is None)

        .. note::
            In the current implementation setting, `spec_state=True` might break the set `limit` and return less records than stated in the set `limit`.

        **Examples:**

        .. code-block:: python

            ai_service_details = await client._ai_services.aget_details(
                ai_service_id
            )
            ai_service_details = await client._ai_services.aget_details(
                ai_service_name
            )
            ai_service_details = await client._ai_services.aget_details()
            ai_service_details = await client._ai_services.aget_details(limit=100)
            ai_service_details = await client._ai_services.aget_details(
                limit=100, get_all=True
            )
            ai_service_details = []
            async for entry in await client._ai_services.aget_details(
                limit=100, asynchronous=True, get_all=True
            ):
                ai_service_details.extend(entry)

        """
        ...
    
    @classmethod
    def get_id(cls, ai_service_details: dict) -> str:
        """Get the ID of a stored AI service.

        :param ai_service_details: metadata of the stored AI service
        :type ai_service_details: dict

        :return: ID of the stored AI service
        :rtype: str

        **Example:**

        .. code-block:: python

            ai_service_details = client.repository.get_ai_service_details(
                ai_service_id
            )
            ai_service_id = client._ai_services.get_id(ai_service_details)
        """
        ...
    
    def list(self, limit: int | None = ...) -> pandas.DataFrame:
        """Return stored AI services in a table format.

        :param limit: limit number of fetched records
        :type limit: int, optional

        :return: pandas.DataFrame with listed AI services
        :rtype: pandas.DataFrame

        **Example:**

        .. code-block:: python

            client._ai_services.list()
        """
        ...
    
    def create_revision(self, ai_service_id: str) -> dict:
        """Create a new AI service revision.

        :param ai_service_id: unique ID of the AI service
        :type ai_service_id: str

        :return: revised metadata of the stored AI service
        :rtype: dict

        **Example:**

        .. code-block:: python

            client._ai_services.create_revision(ai_service_id)
        """
        ...
    
    async def acreate_revision(self, ai_service_id: str) -> dict:
        """Create a new AI service revision asynchronously.

        :param ai_service_id: unique ID of the AI service
        :type ai_service_id: str

        :return: revised metadata of the stored AI service
        :rtype: dict

        **Example:**

        .. code-block:: python

            await client._ai_services.acreate_revision(ai_service_id)
        """
        ...
    
    def get_revision_details(self, ai_service_id: str, rev_id: str) -> dict:
        """Get the metadata of a specific revision of a stored AI service.

        :param ai_service_id: definition of the stored AI service
        :type ai_service_id: str

        :param rev_id: unique ID of the AI service revision
        :type rev_id: str

        :return: metadata of the stored AI service revision
        :rtype: dict

        **Example:**

        .. code-block:: python

            ai_service_revision_details = client._ai_services.get_revision_details(
                ai_service_id, rev_id
            )

        """
        ...
    
    async def aget_revision_details(self, ai_service_id: str, rev_id: str) -> dict:
        """Get the metadata of a specific revision of a stored AI service asynchronously.

        :param ai_service_id: definition of the stored AI service
        :type ai_service_id: str

        :param rev_id: unique ID of the AI service revision
        :type rev_id: str

        :return: metadata of the stored AI service revision
        :rtype: dict

        **Example:**

        .. code-block:: python

            ai_service_revision_details = (
                await client._ai_services.aget_revision_details(
                    ai_service_id, rev_id
                )
            )

        """
        ...
    
    def list_revisions(self, ai_service_id: str, limit: int | None = ...) -> pandas.DataFrame:
        """Print all revisions for a given AI service ID in a table format.

        :param ai_service_id: unique ID of the stored AI service
        :type ai_service_id: str

        :param limit: limit number of fetched records
        :type limit: int, optional

        :return: pandas.DataFrame with listed revisions
        :rtype: pandas.DataFrame

        **Example:**

        .. code-block:: python

            client._ai_services.list_revisions(ai_service_id)

        """
        ...
    


