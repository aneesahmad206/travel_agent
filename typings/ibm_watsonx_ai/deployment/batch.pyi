"""
This type stub file was generated by pyright.
"""

from typing import Any, TYPE_CHECKING
from pandas import DataFrame
from ..helpers import DataConnection
from .base_deployment import BaseDeployment
from numpy import ndarray
from ..credentials import Credentials
from ..workspace import WorkSpace

if TYPE_CHECKING:
    ...
__all__ = ["Batch"]
class Batch(BaseDeployment):
    """The Batch Deployment class.
    With this class object, you can manage any batch deployment.

    :param source_instance_credentials: credentials to the instance where the training was performed
    :type source_instance_credentials: dict

    :param source_project_id: ID of the Watson Studio project where the training was performed
    :type source_project_id: str, optional

    :param source_space_id: ID of the Watson Studio Space where the training was performed
    :type source_space_id: str, optional

    :param target_instance_credentials: credentials to the instance where you want to deploy
    :type target_instance_credentials: dict

    :param target_project_id: ID of the Watson Studio project where you want to deploy
    :type target_project_id: str, optional

    :param target_space_id: ID of the Watson Studio Space where you want to deploy
    :type target_space_id: str, optional

    """
    def __init__(self, source_instance_credentials: Credentials | WorkSpace | None = ..., source_project_id: str | None = ..., source_space_id: str | None = ..., target_instance_credentials: Credentials | WorkSpace | None = ..., target_project_id: str | None = ..., target_space_id: str | None = ..., project_id: str | None = ..., space_id: str | None = ..., **kwargs: Any) -> None:
        ...
    
    def __repr__(self) -> str:
        ...
    
    def __str__(self) -> str:
        ...
    
    def score(self, **kwargs: Any) -> dict:
        ...
    
    def create(self, model: str, deployment_name: str, metadata: dict | None = ..., training_data: DataFrame | ndarray | None = ..., training_target: DataFrame | ndarray | None = ..., experiment_run_id: str | None = ..., hardware_spec: str | dict | None = ..., astype: str = ...) -> None:
        """Create a deployment from a model.

        :param model: name of the AutoAI model
        :type model: str

        :param deployment_name: name of the deployment
        :type deployment_name: str

        :param training_data: training data for the model
        :type training_data: pandas.DataFrame or numpy.ndarray, optional

        :param training_target: target/label data for the model
        :type training_target: pandas.DataFrame or numpy.ndarray, optional

        :param metadata: meta properties of the model
        :type metadata: dict, optional

        :param experiment_run_id: ID of a training/experiment (only applicable for AutoAI deployments)
        :type experiment_run_id: str, optional

        :param hardware_spec: hardware specification name of the deployment
        :type hardware_spec: str | dict, optional

        :param astype: type of stored model [hybrid, onnx]
        :type astype: str, optional

        **Example:**

        .. code-block:: python

            from ibm_watsonx_ai.deployment import Batch

            deployment = Batch(
                source_instance_credentials=Credentials(...),
                source_project_id="...",
                target_space_id="...",
            )

            deployment.create(
                experiment_run_id="...",
                model=model,
                deployment_name="My new deployment"
                hardware_spec="L",
            )
        """
        ...
    
    @BaseDeployment._project_to_space_to_project
    def get_params(self) -> dict:
        """Get deployment parameters."""
        ...
    
    @BaseDeployment._project_to_space_to_project
    def run_job(self, payload: (DataFrame | list[DataConnection] | dict[str, DataFrame] | dict[str, DataConnection]) = ..., output_data_reference: DataConnection | None = ..., transaction_id: str | None = ..., background_mode: bool = ..., hardware_spec: str | dict | None = ...) -> dict | DataConnection:
        """Batch scoring job. Payload or Payload data reference is required.
        Passed to the Service where the model has been deployed.

        :param payload: DataFrame that contains data to test the model or data storage connection details
            that inform the model where the payload data is stored
        :type payload: pandas.DataFrame or List[DataConnection] or Dict

        :param output_data_reference: DataConnection to the output COS for storing predictions,
             required only when DataConnections are used as a payload
        :type output_data_reference: DataConnection, optional

        :param transaction_id: ID under which the records should be saved in the payload table
            in IBM OpenScale
        :type transaction_id: str, optional

        :param background_mode: indicator whether the score() method will run in the background (async) or (sync)
        :type background_mode: bool, optional

        :param hardware_spec: hardware specification name for the scoring job
        :type hardware_spec: str | dict, optional

        :return: details of the scoring job
        :rtype: dict

        **Examples**

        .. code-block:: python

            score_details = batch_service.run_job(payload=test_data)
            print(score_details["entity"]["scoring"])

            # Result:
            # {
            #     "input_data": [
            #         {
            #             "fields": [
            #                 "sepal_length",
            #                 "sepal_width",
            #                 "petal_length",
            #                 "petal_width",
            #             ],
            #             "values": [[4.9, 3.0, 1.4, 0.2]],
            #         }
            #     ],
            #     "predictions": [
            #         {
            #             "fields": ["prediction", "probability"],
            #             "values": [
            #                 [
            #                     "setosa",
            #                     [
            #                         0.9999320742502246,
            #                         5.1519823540224506e-05,
            #                         1.6405926235405522e-05,
            #                     ],
            #                 ]
            #             ],
            #         }
            #     ],
            # }

            payload_reference = DataConnection(
                location=DSLocation(asset_id=asset_id)
            )
            score_details = batch_service.run_job(
                payload=payload_reference, output_data_filename="scoring_output.csv"
            )
            score_details = batch_service.run_job(
                payload={"observations": payload_reference}
            )
            score_details = batch_service.run_job(payload=[payload_reference])
            score_details = batch_service.run_job(
                payload={
                    "observations": payload_reference,
                    "supporting_features": supporting_features_reference,  # supporting features time series forecasting scenario
                }
            )
            score_details = batch_service.run_job(
                payload=test_df, hardware_spec="S"
            )
            score_details = batch_service.run_job(
                payload=test_df, hardware_spec=TShirtSize.L
            )
        """
        ...
    
    @BaseDeployment._project_to_space_to_project
    def rerun_job(self, scoring_job_id: str, background_mode: bool = ...) -> dict | DataFrame | DataConnection:
        """Rerun scoring job with the same parameters as job described by `scoring_job_id`.

        :param scoring_job_id: ID of the described scoring job
        :type scoring_job_id: str

        :param background_mode: indicator whether the score_rerun() method will run in the background (async) or (sync)
        :type background_mode: bool, optional

        :return: details of the scoring job
        :rtype: dict

        **Example:**

        .. code-block:: python

            scoring_details = deployment.score_rerun(scoring_job_id)
        """
        ...
    
    @BaseDeployment._project_to_space_to_project
    def delete(self, deployment_id: str | None = ...) -> None:
        """Delete a deployment.

        :param deployment_id: ID of the deployment to be deleted, if empty, current deployment will be deleted
        :type deployment_id: str, optional

        **Example:**

        .. code-block:: python

            deployment = Batch(workspace=...)
            # Delete current deployment
            deployment.delete()
            # Or delete a specific deployment
            deployment.delete(deployment_id="...")
        """
        ...
    
    @BaseDeployment._project_to_space_to_project
    def list(self, limit: int | None = ...) -> DataFrame:
        """List deployments.

        :param limit: set the limit for number of listed deployments,
            default is `None` (all deployments should be fetched)
        :type limit: int, optional

        :return: Pandas DataFrame with information about deployments
        :rtype: pandas.DataFrame

        **Example:**

        .. code-block:: python

            deployment = Batch(workspace=...)
            deployments_list = deployment.list()
            print(deployments_list)

            # Result:
            #                  created_at  ...  status
            # 0  2020-03-06T10:50:49.401Z  ...   ready
            # 1  2020-03-06T13:16:09.789Z  ...   ready
            # 4  2020-03-11T14:46:36.035Z  ...  failed
            # 3  2020-03-11T14:49:55.052Z  ...  failed
            # 2  2020-03-11T15:13:53.708Z  ...   ready
        """
        ...
    
    @BaseDeployment._project_to_space_to_project
    def get(self, deployment_id: str) -> None:
        """Get a deployment.

        :param deployment_id: ID of the deployment
        :type deployment_id: str

        **Example:**

        .. code-block:: python

            deployment = Batch(workspace=...)
            deployment.get(deployment_id="...")
        """
        ...
    
    @BaseDeployment._project_to_space_to_project
    def get_job_params(self, scoring_job_id: str | None = ...) -> dict:
        """Get batch deployment job parameters.

        :param scoring_job_id: ID of the scoring job
        :type scoring_job_id: str

        :return: parameters of the scoring job
        :rtype: dict
        """
        ...
    
    @BaseDeployment._project_to_space_to_project
    def get_job_status(self, scoring_job_id: str) -> dict:
        """Get the status of a scoring job.

        :param scoring_job_id: ID of the scoring job
        :type scoring_job_id: str

        :return: dictionary with state of the scoring job (one of: [completed, failed, starting, queued])
            and additional details if they exist
        :rtype: dict
        """
        ...
    
    @BaseDeployment._project_to_space_to_project
    def get_job_result(self, scoring_job_id: str) -> DataFrame:
        """Get batch deployment results of a scoring job.

        :param scoring_job_id: ID of the scoring job
        :type scoring_job_id: str

        :return: batch deployment results of the scoring job
        :rtype: pandas.DataFrame

        :raises MissingScoringResults: in case of incompleted or failed job
            `MissingScoringResults` scoring exception is raised
        """
        ...
    
    @BaseDeployment._project_to_space_to_project
    def get_job_id(self, batch_scoring_details: dict) -> str:
        """Get the ID from batch scoring details."""
        ...
    
    @BaseDeployment._project_to_space_to_project
    def list_jobs(self) -> DataFrame:
        """Returns pandas DataFrame with a list of deployment jobs"""
        ...
    


