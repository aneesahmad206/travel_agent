"""
This type stub file was generated by pyright.
"""

from typing import List, TYPE_CHECKING, Tuple, Union
from numpy import ndarray
from pandas import DataFrame, Series
from ibm_watsonx_ai.utils.autoai.enums import ClassificationAlgorithms, Metrics, PipelineTypes, PredictionType, RegressionAlgorithms, Transformers
from .base_auto_pipelines import BaseAutoPipelines
from ibm_boto3 import resource
from lale.operators import TrainablePipeline
from sklearn.pipeline import Pipeline
from ibm_watsonx_ai.helpers import DataConnection

if TYPE_CHECKING:
    ...
__all__ = ["LocalAutoPipelines"]
DATE_FORMAT = ...
class LocalAutoPipelines(BaseAutoPipelines):
    """LocalAutoPipelines class for pipeline operation automation.

    :param name: name for the AutoPipelines
    :type name: str

    :param prediction_type: type of the prediction
    :type prediction_type: PredictionType

    :param prediction_column: name of the target/label column
    :type prediction_column: str

    :param scoring: type of the metric to optimize with
    :type scoring: Metrics

    :param desc: description
    :type desc: str, optional

    :param holdout_size: percentage of the entire dataset to leave as a holdout, for AutoAI Forecasting it can be a number of rows of data
    :type holdout_size: float | int, optional

    :param max_num_daub_ensembles: maximum number (top-K ranked by DAUB model selection) of the selected algorithm,
        or estimator types, for example `LGBMClassifierEstimator`, `XGBoostClassifierEstimator`,
        or `LogisticRegressionEstimator` to use in pipeline composition, the default is None that means
        the true default value will be determined by the internal different algorithms,
        where only the highest ranked by model selection algorithm type is used
    :type max_num_daub_ensembles: int, optional

    :param train_sample_rows_test_size: training data sampling percentage
    :type train_sample_rows_test_size: float, optional

    :param include_only_estimators: list of estimators to include in computation process
    :type include_only_estimators: list[ClassificationAlgorithms or RegressionAlgorithms], optional

    :param cognito_transform_names: list of transformers to include in the feature enginnering computation process,
        see: AutoAI.Transformers
    :type cognito_transform_names: list[Transformers], optional

    :param _data_clients: internal argument to auto-gen notebooks
    :type _data_clients: list[client or resource], optional

    :param _result_client: internal argument to auto-gen notebooks
    :type _result_client: client or resource, optional

    :param _force_local_scenario: internal argument to force local scenario enablement
    :type _force_local_scenario: bool, optional
    """
    def __init__(self, name: str, prediction_type: PredictionType, prediction_column: str, scoring: Metrics, desc: str = ..., holdout_size: float | int = ..., max_num_daub_ensembles: int = ..., train_sample_rows_test_size: float = ..., include_only_estimators: List[Union[ClassificationAlgorithms, RegressionAlgorithms]] = ..., cognito_transform_names: List[Transformers] = ..., positive_label: str = ..., _data_clients: List[Tuple[DataConnection, resource]] = ..., _result_client: Tuple[DataConnection, resource] = ..., _force_local_scenario: bool = ..., **_additional_params) -> None:
        ...
    
    def get_params(self) -> dict:
        """Get configuration parameters of AutoPipelines.

        :return: AutoPipelines parameters
        :rtype: dict

        **Example:**

        .. code-block:: python

            from ibm_watsonx_ai.experiment import AutoAI

            experiment = AutoAI()
            local_optimizer = experiment.optimizer()

            local_optimizer.get_params()

            # Result:
            # {
            #     'name': 'test name',
            #     'desc': 'test description',
            #     'prediction_type': 'classification',
            #     'prediction_column': 'y',
            #     'scoring': 'roc_auc',
            #     'holdout_size': 0.1,
            #     'max_num_daub_ensembles': 1,
            #     'train_sample_rows_test_size': 0.8,
            #     'include_only_estimators': ["ExtraTreesClassifierEstimator",
            #                                     "GradientBoostingClassifierEstimator",
            #                                     "LGBMClassifierEstimator",
            #                                     "LogisticRegressionEstimator",
            #                                     "RandomForestClassifierEstimator",
            #                                     "XGBClassifierEstimator"]
            # }
        """
        ...
    
    def fit(self, X: DataFrame, y: Series) -> Pipeline:
        """Run a training process of AutoAI locally.

        :param X: training dataset
        :type X: pandas.DataFrame

        :param y: target values
        :type y: pandas.Series

        :return: pipeline model (best found)
        :rtype: Pipeline

        **Example:**

        .. code-block:: python

            from ibm_watsonx_ai.experiment import AutoAI

            experiment = AutoAI()
            local_optimizer = experiment.optimizer()

            fitted_best_model = local_optimizer.fit(X=test_data_x, y=test_data_y)
        """
        ...
    
    def get_holdout_data(self) -> Tuple[DataFrame, ndarray]:
        """Provide holdout part of the training dataset (X and y) to the user.

        :return: X, y
        :rtype: tuple[DataFrame, ndarray]

        **Example:**

        .. code-block:: python

            from ibm_watsonx_ai.experiment import AutoAI

            experiment = AutoAI()
            local_optimizer = experiment.optimizer()

            holdout_data = local_optimizer.get_holdout_data()
        """
        ...
    
    def summary(self) -> DataFrame:
        """Prints AutoPipelineOptimizer Pipelines details (autoai trained pipelines).

        :return: Pandas DataFrame with computed pipelines and ML metrics
        :rtype: pandas.DataFrame

        **Example:**

        .. code-block:: python

            from ibm_watsonx_ai.experiment import AutoAI

            experiment = AutoAI()
            local_optimizer = experiment.optimizer()

            local_optimizer.summary()

            # Result:
            #                training_normalized_gini_coefficient  ...  training_f1
            # Pipeline Name                                        ...
            # Pipeline_3                                 0.359173  ...     0.449197
            # Pipeline_4                                 0.359173  ...     0.449197
            # Pipeline_1                                 0.358124  ...     0.449057
            # Pipeline_2                                 0.358124  ...     0.449057
        """
        ...
    
    def get_pipeline_details(self, pipeline_name: str = ...) -> dict:
        """Fetch specific pipeline details, eg. steps etc.

        :param pipeline_name: pipeline name eg. Pipeline_1, if not specified, best pipeline parameters will be fetched
        :type pipeline_name: str, optional

        :return: pipeline parameters
        :rtype: dict

        **Example:**

        .. code-block:: python

            from ibm_watsonx_ai.experiment import AutoAI

            experiment = AutoAI()
            local_optimizer = experiment.optimizer()

            pipeline_details = local_optimizer.get_pipeline_details(
                pipeline_name="Pipeline_1"
            )
        """
        ...
    
    def get_pipeline(self, pipeline_name: str = ..., astype: PipelineTypes = ..., persist: bool = ...) -> Union[Pipeline, TrainablePipeline]:
        """Get specified computed pipeline.

        :param pipeline_name: pipeline name, if you want to see the pipelines names, please use summary() method,
            if this parameter is None, the best pipeline will be fetched
        : type pipeline_name: str, optional

        :param astype: type of returned pipeline model, if not specified, lale type is chosen
        :type astype: PipelineTypes, optional

        :param persist: indicates if selected pipeline should be stored locally
        :type persist: bool, optional

        :return: Scikit-Learn pipeline or Lale TrainablePipeline
        :rtype: Pipeline or TrainablePipeline

        See also LocalAutoPipelines.summary().

        **Example:**

        .. code-block:: python

            from ibm_watsonx_ai.experiment import AutoAI

            experiment = AutoAI()
            local_optimizer = experiment.optimizer()

            pipeline_1 = local_optimizer.get_pipeline(pipeline_name="Pipeline_1")
            pipeline_2 = local_optimizer.get_pipeline(
                pipeline_name="Pipeline_1", astype=PipelineTypes.LALE
            )
            pipeline_3 = local_optimizer.get_pipeline(
                pipeline_name="Pipeline_1", astype=PipelineTypes.SKLEARN
            )
            type(pipeline_3)

            # Result:
            # <class 'sklearn.pipeline.Pipeline'>

        """
        ...
    
    def get_pipeline_notebook(self, pipeline_name: str = ..., persist: bool = ...) -> Union[Pipeline, TrainablePipeline]:
        ...
    
    def predict(self, X: Union[DataFrame, ndarray]) -> ndarray:
        """Predict method called on top of the best computed pipeline.

        :param X: test data for prediction
        :type X: numpy.ndarray or pandas.DataFrame

        :return: model predictions
        :rtype: numpy.ndarray

        **Example:**

        .. code-block:: python

            from ibm_watsonx_ai.experiment import AutoAI

            experiment = AutoAI()
            local_optimizer = experiment.optimizer()

            predictions = local_optimizer.predict(X=test_data)
        """
        ...
    
    def get_data_connections(self) -> List[DataConnection]:
        """Provides list of DataConnections with training data that user specified.

        :return: list of DataConnections with populated optimizer parameters
        :rtype: list[DataConnection]
        """
        ...
    


