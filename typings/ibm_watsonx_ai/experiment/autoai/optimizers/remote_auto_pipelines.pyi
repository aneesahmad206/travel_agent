"""
This type stub file was generated by pyright.
"""

from typing import List, TYPE_CHECKING, Union
from numpy import ndarray
from pandas import DataFrame
from ibm_watsonx_ai.experiment.autoai.engines import ServiceEngine, WMLEngine
from ibm_watsonx_ai.helpers.connections import DataConnection
from ibm_watsonx_ai.utils.autoai.enums import BatchedClassificationAlgorithms, BatchedRegressionAlgorithms, ClassificationAlgorithms, ForecastingPipelineTypes, Metrics, PipelineTypes, PredictionType, RegressionAlgorithms, TShirtSize, TimeseriesAnomalyPredictionPipelineTypes, Transformers
from .base_auto_pipelines import BaseAutoPipelines
from lale.operators import TrainablePipeline
from sklearn.pipeline import Pipeline

if TYPE_CHECKING:
    ...
__all__ = ["RemoteAutoPipelines"]
class RemoteAutoPipelines(BaseAutoPipelines):
    """RemoteAutoPipelines class for pipeline operation automation on Service.

    :param name: name for the AutoPipelines
    :type name: str

    :param prediction_type: type of the prediction
    :type prediction_type: PredictionType

    :param prediction_column: name of the target/label column
    :type prediction_column: str

    :param scoring: type of the metric to optimize with
    :type scoring: Metrics

    :param engine: engine for remote work on Service instance
    :type engine:  ServiceEngine or WMLEngine (deprecated)

    :param desc: description
    :type desc: str, optional

    :param holdout_size: percentage of the entire dataset to leave as a holdout, for AutoAI Forecasting it can be a number of rows of data
    :type holdout_size: float | int, optional

    :param max_num_daub_ensembles: maximum number (top-K ranked by DAUB model selection) of the selected algorithm,
        or estimator types, for example `LGBMClassifierEstimator`, `XGBoostClassifierEstimator`, or
        `LogisticRegressionEstimator` to use in pipeline composition, the default is `None` that means
        the true default value will be determined by the internal different algorithms, where only
        the highest ranked by model selection algorithm type is used
    :type max_num_daub_ensembles: int, optional

    :param train_sample_rows_test_size: training data sampling percentage
    :type train_sample_rows_test_size: float, optional

    :param include_only_estimators: list of estimators to include in computation process
    :type include_only_estimators: list[ClassificationAlgorithms or RegressionAlgorithms], optional

    :param cognito_transform_names: list of transformers to include in the feature enginnering computation process,
        see: AutoAI.Transformers
    :type cognito_transform_names: list[Transformers], optional

    :param csv_separator: the separator, or list of separators to try for separating columns in a CSV file,
        not used if the file_name is not a CSV file, default is ','
    :type csv_separator: list[str] or str, optional

    :param excel_sheet: name of the excel sheet to use, only use when xlsx file is an input,
        support for number of the sheet is deprecated, by default first sheet is used
    :type excel_sheet: str, optional

    :param encoding: encoding type for CSV training file
    :type encoding: str, optional

    :param positive_label: the positive class to report when binary classification, when multiclass or regression,
        this will be ignored
    :type positive_label: str, optional

    :param t_shirt_size: the size of the remote AutoAI POD instance (computing resources),
        only applicable to a remote scenario
    :type t_shirt_size: TShirtSize, optional

    :param time_ordered_data: defines user preference about time-based analise. If True, the analysis will
        consider the data as time-ordered and time-based. Supported only for regression.
    :type time_ordered_data: bool, optional

    :param feature_selector_mode: defines if feature selector should be triggered ["on", "off", "auto"],
                the "auto" mode analyzes the impact of removing insignificant features, if there is drop in accuracy,
                the PCA is applied to insignificant features, principal components describing variance in 30% or higher
                are selected in place of insignificant features and the model is evaluated again, if there is still drop
                in accuracy all features are used
                the "on" mode removes all insignificant features (0.0. importance), the feature selector is applied during
                cognito phase (applicable to pipelines with feature engineering stage)
    :type feature_selector_mode: str, optional
    """
    def __init__(self, name: str, prediction_type: PredictionType, prediction_column: str, prediction_columns: List[str], timestamp_column_name: str, engine: Union[WMLEngine, ServiceEngine], scoring: Metrics = ..., desc: str = ..., holdout_size: float | int | None = ..., max_num_daub_ensembles: int = ..., t_shirt_size: TShirtSize = ..., train_sample_rows_test_size: float = ..., include_only_estimators: List[Union[ClassificationAlgorithms, RegressionAlgorithms]] = ..., include_batched_ensemble_estimators: List[Union[BatchedClassificationAlgorithms, BatchedRegressionAlgorithms]] = ..., backtest_num: int = ..., lookback_window: int = ..., forecast_window: int = ..., backtest_gap_length: int = ..., cognito_transform_names: List[Transformers] = ..., csv_separator: Union[List[str], str] = ..., excel_sheet: Union[str, int] = ..., encoding: str = ..., positive_label: str = ..., drop_duplicates: bool = ..., outliers_columns: list = ..., text_processing: bool = ..., word2vec_feature_number: int = ..., daub_give_priority_to_runtime: float = ..., notebooks=..., autoai_pod_version=..., text_columns_names=..., n_parallel_data_connections=..., test_data_csv_separator: Union[List[str], str] = ..., test_data_excel_sheet: Union[str, int] = ..., test_data_encoding: str = ..., sampling_type=..., sample_size_limit=..., sample_rows_limit=..., sample_percentage_limit=..., number_of_batch_rows=..., categorical_imputation_strategy=..., numerical_imputation_strategy=..., numerical_imputation_value=..., imputation_threshold=..., fairness_info: dict = ..., retrain_on_holdout: bool = ..., feature_columns: List[str] = ..., pipeline_types: List[Union[ForecastingPipelineTypes, TimeseriesAnomalyPredictionPipelineTypes]] = ..., supporting_features_at_forecast: bool = ..., categorical_columns: list = ..., numerical_columns: list = ..., confidence_level: float = ..., incremental_learning: bool = ..., early_stop_enabled: bool = ..., early_stop_window_size: int = ..., time_ordered_data: bool = ..., feature_selector_mode: str = ..., **kwargs) -> None:
        ...
    
    def get_params(self) -> dict:
        """Get configuration parameters of AutoPipelines.

        :return: AutoPipelines parameters
        :rtype: dict

        **Example:**

        .. code-block:: python

            from ibm_watsonx_ai.experiment import AutoAI

            experiment = AutoAI(credentials, ...)
            remote_optimizer = experiment.optimizer(...)

            remote_optimizer.get_params()

            # Result:
            # {
            #     'name': 'test name',
            #     'desc': 'test description',
            #     'prediction_type': 'classification',
            #     'prediction_column': 'y',
            #     'scoring': 'roc_auc',
            #     'holdout_size': 0.1,
            #     'max_num_daub_ensembles': 1,
            #     't_shirt_size': 'm',
            #     'train_sample_rows_test_size': 0.8,
            #    'include_only_estimators': ["ExtraTreesClassifierEstimator",
            #                                "GradientBoostingClassifierEstimator",
            #                                "LGBMClassifierEstimator",
            #                                "LogisticRegressionEstimator",
            #                                "RandomForestClassifierEstimator",
            #                                "XGBClassifierEstimator"]
            # }
        """
        ...
    
    def fit(self, train_data: DataFrame = ..., *, training_data_reference: List[DataConnection] = ..., training_results_reference: DataConnection = ..., background_mode=..., test_data_references: List[DataConnection] = ..., training_data_references: List[DataConnection] = ...) -> dict:
        """Run a training process on Service of autoai on top of the training data referenced by DataConnection.

        :param training_data_reference: data storage connection details to inform where training data is stored,
            deprecated parameter, use `training_data_references` instead

        :param training_data_references: data storage connection details to inform where training data is stored,
            new version of `training_data_reference`
        :type training_data_references: list[DataConnection]

        :param training_results_reference: data storage connection details to store pipeline training results,
            not applicable on CP4D
        :type training_results_reference: DataConnection, optional

        :param background_mode: indicator if fit() method will run in background (async) or (sync)
        :type background_mode: bool, optional

        :param test_data_references: data storage connection details to inform where test / holdout data is stored
        :type test_data_references: list[DataConnection], optional

        :return: run details
        :rtype: dict

        **Example:**

        .. code-block:: python

            from ibm_watsonx_ai.experiment import AutoAI
            from ibm_watsonx_ai.helpers import DataConnection, S3Location

            experiment = AutoAI(credentials, ...)
            remote_optimizer = experiment.optimizer(...)

            remote_optimizer.fit(
                training_data_reference=[DataConnection(
                    connection_asset_id=connection_id,
                    location=S3Location(
                        bucket='automl',
                        path='german_credit_data_biased_training.csv')
                    )
                )],
                DataConnection(
                    connection_asset_id=connection_id,
                    location=S3Location(
                        bucket='automl',
                        path='')
                    )
                ),
                background_mode=False)
        """
        ...
    
    def determine_result_reference(self, results_reference, data_references, result_path): # -> DataConnection:
        ...
    
    def get_run_status(self) -> str:
        """Check status/state of initialized AutoPipelines run if ran in background mode.

        :return: run status details
        :rtype: dict

        **Example:**

            from ibm_watsonx_ai.experiment import AutoAI
            experiment = AutoAI(credentials, ...)
            remote_optimizer = experiment.optimizer(...)

            remote_optimizer.get_run_status()

            # Result:
            # 'completed'
        """
        ...
    
    def get_run_details(self, include_metrics: bool = ..., _internal=...) -> dict:
        """Get fit/run details.

        :param include_metrics: indicates to include metrics in the training details output
        :type include_metrics: bool, optional

        :return: AutoPipelineOptimizer fit/run details
        :rtype: dict

        **Example:**

        .. code-block:: python

            from ibm_watsonx_ai.experiment import AutoAI

            experiment = AutoAI(credentials, ...)
            remote_optimizer = experiment.optimizer(...)

            remote_optimizer.get_run_details()
        """
        ...
    
    def cancel_run(self) -> None:
        """Cancels an AutoAI run."""
        ...
    
    def summary(self, scoring: str = ..., sort_by_holdout_score: bool = ...) -> DataFrame:
        """Print AutoPipelineOptimizer Pipelines details (autoai trained pipelines).

        :param scoring: scoring metric which user wants to use to sort pipelines by,
            when not provided use optimized one
        :type scoring: string, optional

        :param sort_by_holdout_score: indicates if we want to sort pipelines by holdout metric or by training one,
            by default use holdout metric
        :type sort_by_holdout_score: bool, optional

        :return: computed pipelines and ML metrics
        :rtype: pandas.DataFrame

        **Example:**

        .. code-block:: python

            from ibm_watsonx_ai.experiment import AutoAI

            experiment = AutoAI(credentials, ...)
            remote_optimizer = experiment.optimizer(...)

            remote_optimizer.summary()

            # Result:
            #                training_normalized_gini_coefficient  ...  training_f1
            # Pipeline Name                                        ...
            # Pipeline_3                                 0.359173  ...     0.449197
            # Pipeline_4                                 0.359173  ...     0.449197
            # Pipeline_1                                 0.358124  ...     0.449057
            # Pipeline_2                                 0.358124  ...     0.449057
        """
        ...
    
    def get_pipeline_details(self, pipeline_name: str = ...) -> dict:
        """Fetch specific pipeline details, eg. steps etc.

        :param pipeline_name: pipeline name eg. Pipeline_1, if not specified, best pipeline parameters will be fetched
        :type pipeline_name: str, optional

        :return: pipeline parameters
        :rtype: dict

        **Example:**

        .. code-block:: python

            from ibm_watsonx_ai.experiment import AutoAI

            experiment = AutoAI(credentials, ...)
            remote_optimizer = experiment.optimizer(...)

            remote_optimizer.get_pipeline_details()
            remote_optimizer.get_pipeline_details(pipeline_name="Pipeline_4")

            # Result:
            # {
            #     'composition_steps': ['TrainingDataset_full_4521_16', 'Split_TrainingHoldout',
            #                           'TrainingDataset_full_4068_16', 'Preprocessor_default', 'DAUB'],
            #     'pipeline_nodes': ['PreprocessingTransformer', 'GradientBoostingClassifierEstimator']
            # }
        """
        ...
    
    def get_pipeline(self, pipeline_name: str = ..., astype: PipelineTypes = ..., persist: bool = ...) -> Union[Pipeline, TrainablePipeline]:
        """Download specified pipeline from Service.

        :param pipeline_name: pipeline name, if you want to see the pipelines names, please use summary() method,
            if this parameter is None, the best pipeline will be fetched
        :type pipeline_name: str, optional

        :param astype: type of returned pipeline model, if not specified, lale type is chosen
        :type astype: PipelineTypes, optional

        :param persist: indicates if selected pipeline should be stored locally
        :type persist: bool, optional

        :return: Scikit-Learn pipeline
        :rtype: Pipeline or TrainablePipeline

        See also RemoteAutoPipelines.summary().

        **Example:**

        .. code-block:: python

            from ibm_watsonx_ai.experiment import AutoAI

            experiment = AutoAI(credentials, ...)
            remote_optimizer = experiment.optimizer(...)

            pipeline_1 = remote_optimizer.get_pipeline(pipeline_name="Pipeline_1")
            pipeline_2 = remote_optimizer.get_pipeline(
                pipeline_name="Pipeline_1", astype=AutoAI.PipelineTypes.LALE
            )
            pipeline_3 = remote_optimizer.get_pipeline(
                pipeline_name="Pipeline_1", astype=AutoAI.PipelineTypes.SKLEARN
            )
            type(pipeline_3)
            # <class 'sklearn.pipeline.Pipeline'>
            pipeline_4 = remote_optimizer.get_pipeline(
                pipeline_name="Pipeline_1", persist=True
            )
            # Selected pipeline stored under: "absolute_local_path_to_model/model.pickle"

        """
        ...
    
    def get_pipeline_notebook(self, pipeline_name: str = ..., filename: str = ..., insert_to_cell: bool = ...) -> str:
        """Download specified pipeline notebook from Service.

        :param pipeline_name: pipeline name, if you want to see the pipelines names, please use summary() method,
            if this parameter is None, the best pipeline will be fetched
        :type pipeline_name: str, optional

        :param filename: filename under which the pipeline notebook will be saved
        :type filename: str, optional

        :param insert_to_cell: if run in jupyter notebook, if set inserts the notebook into cell below
        :type insert_to_cell: bool, optional

        :return: path to saved pipeline notebook
        :rtype: str

        See also RemoteAutoPipelines.summary().

        **Example:**

        .. code-block:: python

            from ibm_watsonx_ai.experiment import AutoAI

            experiment = AutoAI(credentials, ...)
            remote_optimizer = experiment.optimizer(...)

            pipeline_notebook_path = remote_optimizer.get_pipeline_notebook(
                pipeline_name="Pipeline_1"
            )

        """
        ...
    
    def predict(self, X: Union[DataFrame, ndarray] = ..., observations: Union[DataFrame, ndarray] = ..., supporting_features: Union[DataFrame, ndarray] = ...) -> ndarray:
        """Predict method called on top of the best fetched pipeline.

        :param X: test data for prediction
        :type X: numpy.ndarray or pandas.DataFrame

        :param observations: new observations of forecasting data that were used to train AutoAI model,
            supported only for forecasting pipelines
        :type observations: numpy.ndarray or pandas.DataFrame

        :param supporting_features: future values of exogenous features, supported only for forecasting pipelines
        :type supporting_features: numpy.ndarray or pandas.DataFrame

        :return: model predictions
        :rtype: numpy.ndarray
        """
        ...
    
    def get_data_connections(self) -> List[DataConnection]:
        """Create DataConnection objects for further user usage
            (eg. to handle data storage connection or to recreate autoai holdout split).

        :return: list of DataConnection with populated optimizer parameters
        :rtype: list[DataConnection]
        """
        ...
    
    def get_test_data_connections(self) -> List[DataConnection]:
        """Create DataConnection objects for further user usage (To recreate autoai holdout that user specified).

        :return: list of DataConnection with populated optimizer parameters
        :rtype: list[DataConnection]
        """
        ...
    


