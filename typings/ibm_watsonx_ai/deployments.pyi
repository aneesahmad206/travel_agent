"""
This type stub file was generated by pyright.
"""

import pandas as pd
from enum import Enum
from typing import Any, AsyncGenerator, Generator, Literal, TYPE_CHECKING, TypeAlias
from ibm_watsonx_ai.metanames import DecisionOptimizationMetaNames, ScoringMetaNames
from ibm_watsonx_ai.wml_resource import WMLResource
from ibm_watsonx_ai import APIClient
from ibm_watsonx_ai.foundation_models.schema import TextChatParameters
from ibm_watsonx_ai.lifecycle import SpecStates

if TYPE_CHECKING:
    ...
lib_checker = ...
ListType: TypeAlias = list
InferenceType: TypeAlias = Literal["text", "text_stream", "chat", "chat_stream"]
class Deployments(WMLResource):
    """Deploy and score published artifacts (models and functions)."""
    DEFAULT_CONCURRENCY_LIMIT = ...
    ConfigurationMetaNames = ...
    ScoringMetaNames = ...
    DecisionOptimizationMetaNames = ...
    class HardwareRequestSizes(str, Enum):
        """
        An enum class that represents the different hardware request sizes
        available.
        """
        Small = ...
        Medium = ...
        Large = ...
    
    
    def __init__(self, client: APIClient) -> None:
        ...
    
    def create(self, artifact_id: str | None = ..., meta_props: dict | None = ..., rev_id: str | None = ..., **kwargs: dict) -> dict:
        """Create a deployment from an artifact. An artifact is a model or function that can be deployed.

        :param artifact_id: ID of the published artifact (the model or function ID)
        :type artifact_id: str

        :param meta_props: meta props. To see the available list of meta names, use:

            .. code-block:: python

                client.deployments.ConfigurationMetaNames.get()

        :type meta_props: dict, optional

        :param rev_id: revision ID of the deployment
        :type rev_id: str, optional

        :return: metadata of the created deployment
        :rtype: dict

        **Example:**

        .. code-block:: python

            meta_props = {
                client.deployments.ConfigurationMetaNames.NAME: "SAMPLE DEPLOYMENT NAME",
                client.deployments.ConfigurationMetaNames.ONLINE: {},
                client.deployments.ConfigurationMetaNames.HARDWARE_SPEC: {
                    "id": "e7ed1d6c-2e89-42d7-aed5-8sb972c1d2b"
                },
                client.deployments.ConfigurationMetaNames.SERVING_NAME: "sample_deployment",
            }
            deployment_details = client.deployments.create(artifact_id, meta_props)

        """
        ...
    
    async def acreate(self, artifact_id: str, meta_props: dict | None = ..., rev_id: str | None = ..., **kwargs: dict) -> dict:
        """Create a deployment from an artifact asynchronously. An artifact is a model or function that can be deployed.

        :param artifact_id: ID of the published artifact (the model or function ID)
        :type artifact_id: str

        :param meta_props: meta props. To see the available list of meta names, use:

            .. code-block:: python

                client.deployments.ConfigurationMetaNames.get()

        :type meta_props: dict, optional

        :param rev_id: revision ID of the deployment
        :type rev_id: str, optional

        :return: metadata of the created deployment
        :rtype: dict

        **Example:**

        .. code-block:: python

            meta_props = {
                client.deployments.ConfigurationMetaNames.NAME: "SAMPLE DEPLOYMENT NAME",
                client.deployments.ConfigurationMetaNames.ONLINE: {},
                client.deployments.ConfigurationMetaNames.HARDWARE_SPEC: {
                    "id": "e7ed1d6c-2e89-42d7-aed5-8sb972c1d2b"
                },
                client.deployments.ConfigurationMetaNames.SERVING_NAME: "sample_deployment",
            }
            deployment_details = await client.deployments.acreate(
                artifact_id, meta_props
            )

        """
        ...
    
    @staticmethod
    def get_uid(deployment_details: dict) -> str:
        """Get deployment_uid from the deployment details.

        *Deprecated:* Use ``get_id(deployment_details)`` instead.

        :param deployment_details: metadata of the deployment
        :type deployment_details: dict

        :return: deployment UID that is used to manage the deployment
        :rtype: str

        **Example:**

        .. code-block:: python

            deployment_uid = client.deployments.get_uid(deployment)

        """
        ...
    
    @staticmethod
    def get_id(deployment_details: dict) -> str:
        """Get the deployment ID from the deployment details.

        :param deployment_details: metadata of the deployment
        :type deployment_details: dict

        :return: deployment ID that is used to manage the deployment
        :rtype: str

        **Example:**

        .. code-block:: python

            deployment_id = client.deployments.get_id(deployment)

        """
        ...
    
    @staticmethod
    def get_href(deployment_details: dict) -> str:
        """Get deployment_href from the deployment details.

        :param deployment_details: metadata of the deployment
        :type deployment_details: dict

        :return: deployment href that is used to manage the deployment
        :rtype: str

        **Example:**

        .. code-block:: python

            deployment_href = client.deployments.get_href(deployment)

        """
        ...
    
    def is_serving_name_available(self, serving_name: str) -> bool:
        """Check if the serving name is available for use.

        :param serving_name: serving name that filters deployments
        :type serving_name: str

        :return: information about whether the serving name is available
        :rtype: bool

        **Example:**

        .. code-block:: python

            is_available = client.deployments.is_serving_name_available("test")

        """
        ...
    
    async def ais_serving_name_available(self, serving_name: str) -> bool:
        """Check if the serving name is available for use asynchronously.

        :param serving_name: serving name that filters deployments
        :type serving_name: str

        :return: information about whether the serving name is available
        :rtype: bool

        **Example:**

        .. code-block:: python

            is_available = await client.deployments.ais_serving_name_available(
                "test"
            )

        """
        ...
    
    def get_details(self, deployment_id: str | None = ..., serving_name: str | None = ..., limit: int | None = ..., asynchronous: bool = ..., get_all: bool = ..., spec_state: SpecStates | None = ..., attempt_activation: bool | None = ..., _silent: bool = ..., **kwargs: Any) -> dict:
        """Get information about deployment(s).
        If deployment_id is not passed, all deployment details are returned.

        :param deployment_id: unique ID of the deployment
        :type deployment_id: str, optional

        :param serving_name: serving name that filters deployments
        :type serving_name: str, optional

        :param limit: limit number of fetched records
        :type limit: int, optional

        :param asynchronous: if True, it will work as a generator
        :type asynchronous: bool, optional

        :param get_all: if True, it will get all entries in 'limited' chunks
        :type get_all: bool, optional

        :param spec_state: software specification state, can be used only when `deployment_id` is None
        :type spec_state: SpecStates, optional

        :param attempt_activation: whether to activate the deployment (wake it up with given `deployment_id`)
        :type attempt_activation: bool, optional

        :return: metadata of the deployment(s)
        :rtype: dict (if ``deployment_id`` is not None) or {"resources": [dict]} otherwise

        **Examples:**

        .. tab-set::

            .. tab-item:: Retrieve single deployment

                .. code-block:: python

                    deployment_details = client.deployments.get_details(deployment_id)
                    deployment_details = client.deployments.get_details(
                        deployment_id=deployment_id
                    )

            .. tab-item:: Retrieve multiple deployments

                .. code-block:: python

                    deployments_details = client.deployments.get_details()
                    deployments_details = client.deployments.get_details(limit=100)
                    deployments_details = client.deployments.get_details(
                        limit=100, get_all=True
                    )

            .. tab-item:: Retrieval using Generator

                .. code-block:: python

                    deployments_details = []
                    for entry in client.deployments.get_details(
                        limit=100, asynchronous=True, get_all=True
                    ):
                        deployments_details.extend(entry["resources"])

        """
        ...
    
    async def aget_details(self, deployment_id: str | None = ..., serving_name: str | None = ..., limit: int | None = ..., asynchronous: bool = ..., get_all: bool = ..., spec_state: SpecStates | None = ..., attempt_activation: bool | None = ..., _silent: bool = ...) -> dict:
        """Get information about deployment(s) asynchronously.
        If deployment_id is not passed, all deployment details are returned.

        :param deployment_id: unique ID of the deployment
        :type deployment_id: str, optional

        :param serving_name: serving name that filters deployments
        :type serving_name: str, optional

        :param limit: limit number of fetched records
        :type limit: int, optional

        :param asynchronous: if True, it will work as a generator
        :type asynchronous: bool, optional

        :param get_all: if True, it will get all entries in 'limited' chunks
        :type get_all: bool, optional

        :param spec_state: software specification state, can be used only when `deployment_id` is None
        :type spec_state: SpecStates, optional

        :param attempt_activation: whether to activate the deployment (wake it up with given `deployment_id`)
        :type attempt_activation: bool, optional

        :return: metadata of the deployment(s)
        :rtype: dict (if ``deployment_id`` is not None) or {"resources": [dict]} otherwise

        **Examples:**

        .. tab-set::

            .. tab-item:: Retrieve single deployment

                .. code-block:: python

                    deployment_details = await client.deployments.aget_details(
                        deployment_id
                    )
                    deployment_details = await client.deployments.aget_details(
                        deployment_id=deployment_id
                    )

            .. tab-item:: Retrieve multiple deployments

                .. code-block:: python

                    deployments_details = await client.deployments.aget_details()
                    deployments_details = await client.deployments.aget_details(limit=100)
                    deployments_details = await client.deployments.aget_details(
                        limit=100, get_all=True
                    )

            .. tab-item:: Retrieval using Generator

                .. code-block:: python

                    deployments_details = []
                    async for entry in await client.deployments.aget_details(
                        limit=100, asynchronous=True, get_all=True
                    ):
                        deployments_details.extend(entry["resources"])

        """
        ...
    
    @staticmethod
    def get_scoring_href(deployment_details: dict) -> str:
        """Get scoring URL from deployment details.

        :param deployment_details: metadata of the deployment
        :type deployment_details: dict

        :return: scoring endpoint URL that is used to make scoring requests
        :rtype: str

        **Example:**

        .. code-block:: python

            scoring_href = client.deployments.get_scoring_href(deployment)

        """
        ...
    
    @staticmethod
    def get_serving_href(deployment_details: dict) -> str:
        """Get serving URL from the deployment details.

        :param deployment_details: metadata of the deployment
        :type deployment_details: dict

        :return: serving endpoint URL that is used to make scoring requests
        :rtype: str

        **Example:**

        .. code-block:: python

            scoring_href = client.deployments.get_serving_href(deployment)

        """
        ...
    
    def delete(self, deployment_id: str | None = ..., **kwargs: Any) -> str:
        """Delete a deployment.

        :param deployment_id: unique ID of the deployment
        :type deployment_id: str

        :return: status "SUCCESS" if deletion is successful
        :rtype: Literal["SUCCESS"]
        :raises: ApiRequestFailure if deletion failed

        **Example:**

        .. code-block:: python

            client.deployments.delete(deployment_id)

        """
        ...
    
    async def adelete(self, deployment_id: str) -> str:
        """Delete a deployment asynchronously.

        :param deployment_id: unique ID of the deployment
        :type deployment_id: str

        :return: status "SUCCESS" if deletion is successful
        :rtype: Literal["SUCCESS"]
        :raises: ApiRequestFailure if deletion failed

        **Example:**

        .. code-block:: python

            await client.deployments.adelete(deployment_id)

        """
        ...
    
    def score(self, deployment_id: str, meta_props: dict, transaction_id: str | None = ...) -> dict:
        """Make scoring requests against the deployed artifact.

        :param deployment_id: unique ID of the deployment to be scored
        :type deployment_id: str

        :param meta_props: meta props for scoring, use ``client.deployments.ScoringMetaNames.show()`` to view the list of ScoringMetaNames
        :type meta_props: dict

        :param transaction_id: transaction ID to be passed with the records during payload logging
        :type transaction_id: str, optional

        :return: scoring result that contains prediction and probability
        :rtype: dict

        .. note::

                * *client.deployments.ScoringMetaNames.INPUT_DATA* is the only metaname valid for sync scoring.
                * The valid payloads for scoring input are either list of values, pandas or numpy dataframes.

        **Example:**

        .. code-block:: python

            scoring_payload = {
                client.deployments.ScoringMetaNames.INPUT_DATA: [
                    {
                        "fields": ["GENDER", "AGE", "MARITAL_STATUS", "PROFESSION"],
                        "values": [
                            ["M", 23, "Single", "Student"],
                            ["M", 55, "Single", "Executive"],
                        ],
                    }
                ]
            }
            predictions = client.deployments.score(deployment_id, scoring_payload)

        """
        ...
    
    async def ascore(self, deployment_id: str, meta_props: dict, transaction_id: str | None = ...) -> dict:
        """Make scoring requests against the deployed artifact asynchronously.

        :param deployment_id: unique ID of the deployment to be scored
        :type deployment_id: str

        :param meta_props: meta props for scoring, use ``client.deployments.ScoringMetaNames.show()`` to view the list of ScoringMetaNames
        :type meta_props: dict

        :param transaction_id: transaction ID to be passed with the records during payload logging
        :type transaction_id: str, optional

        :return: scoring result that contains prediction and probability
        :rtype: dict

        .. note::

                * *client.deployments.ScoringMetaNames.INPUT_DATA* is the only metaname valid for sync scoring.
                * The valid payloads for scoring input are either list of values, pandas or numpy dataframes.

        **Example:**

        .. code-block:: python

            scoring_payload = {
                client.deployments.ScoringMetaNames.INPUT_DATA: [
                    {
                        "fields": ["GENDER", "AGE", "MARITAL_STATUS", "PROFESSION"],
                        "values": [
                            ["M", 23, "Single", "Student"],
                            ["M", 55, "Single", "Executive"],
                        ],
                    }
                ]
            }
            predictions = await client.deployments.ascore(
                deployment_id, scoring_payload
            )

        """
        ...
    
    def get_download_url(self, deployment_details: dict) -> str:
        """Get deployment download URL from the deployment details.

        **Warning:** This method is deprecated and will be removed in the future.

        :param deployment_details: created deployment details
        :type deployment_details: dict

        :return: deployment download URL that is used to get file deployment (for example: Core ML)
        :rtype: str

        **Example:**

        .. code-block:: python

            deployment_url = client.deployments.get_download_url(deployment)

        """
        ...
    
    def list(self, limit: int | None = ..., artifact_type: str | None = ..., include_software_spec_state: bool = ...) -> pd.DataFrame:
        """Returns deployments in a table format.

        :param limit: limit number of fetched records
        :type limit: int, optional

        :param artifact_type: return only deployments with the specified artifact_type
        :type artifact_type: str, optional

        :param include_software_spec_state: include 'SPEC_STATE' and 'SPEC_REPLACEMENT' columns in deployments.
                                    This requires sending more requests and slows down execution, defaults to True
        :type include_software_spec_state: bool, optional

        :return: pandas.DataFrame with the listed deployments
        :rtype: pandas.DataFrame

        **Example:**

        .. code-block:: python

            client.deployments.list()

        """
        ...
    
    def list_jobs(self, limit: int | None = ...) -> pd.DataFrame:
        """Return the async deployment jobs in a table format.

        :param limit: limit number of fetched records
        :type limit: int, optional

        :return: pandas.DataFrame with listed deployment jobs
        :rtype: pandas.DataFrame

        .. note::

            This method list only async deployment jobs created for WML deployment.

        **Example:**

        .. code-block:: python

            client.deployments.list_jobs()

        """
        ...
    
    def update(self, deployment_id: str | None = ..., changes: dict | None = ..., background_mode: bool = ..., **kwargs: Any) -> dict | None:
        """Updates existing deployment metadata. If ASSET is patched, then 'id' field is mandatory
        and it starts a deployment with the provided asset id/rev. Deployment ID remains the same.

        :param deployment_id: unique ID of deployment to be updated
        :type deployment_id: str

        :param changes: elements to be changed, where keys are ConfigurationMetaNames
        :type changes: dict

        :return: metadata of the updated deployment
        :rtype: dict or None

        :param background_mode: indicator whether the update() method will run in the background (async) or not (sync), defaults to False
        :type background_mode: bool, optional

        **Examples**

        .. code-block:: python

            metadata = {
                client.deployments.ConfigurationMetaNames.NAME: "updated_Deployment"
            }
            updated_deployment_details = client.deployments.update(
                deployment_id, changes=metadata
            )

            metadata = {
                client.deployments.ConfigurationMetaNames.ASSET: {
                    "id": "ca0cd864-4582-4732-b365-3165598dc945",
                    "rev": "2",
                }
            }
            deployment_details = client.deployments.update(
                deployment_id, changes=metadata
            )

        """
        ...
    
    async def aupdate(self, deployment_id: str, changes: dict, background_mode: bool = ...) -> dict | None:
        """Updates existing deployment metadata asynchronously. If ASSET is patched, then 'id' field is mandatory
        and it starts a deployment with the provided asset id/rev. Deployment ID remains the same.

        :param deployment_id: unique ID of deployment to be updated
        :type deployment_id: str

        :param changes: elements to be changed, where keys are ConfigurationMetaNames
        :type changes: dict

        :return: metadata of the updated deployment
        :rtype: dict or None

        :param background_mode: indicator whether the update() method will run in the background (async) or not (sync), defaults to False
        :type background_mode: bool, optional

        **Examples**

        .. code-block:: python

            metadata = {
                client.deployments.ConfigurationMetaNames.NAME: "updated_Deployment"
            }
            updated_deployment_details = client.deployments.update(
                deployment_id, changes=metadata
            )

            metadata = {
                client.deployments.ConfigurationMetaNames.ASSET: {
                    "id": "ca0cd864-4582-4732-b365-3165598dc945",
                    "rev": "2",
                }
            }
            deployment_details = await client.deployments.aupdate(
                deployment_id, changes=metadata
            )

        """
        ...
    
    def create_job(self, deployment_id: str, meta_props: dict, retention: int | None = ..., transaction_id: str | None = ..., _asset_id: str | None = ...) -> str | dict:
        """Create an asynchronous deployment job.

        :param deployment_id: unique ID of the deployment
        :type deployment_id: str

        :param meta_props: meta props. To see the available list of metanames,
            use ``client.deployments.ScoringMetaNames.get()``
            or ``client.deployments.DecisionOptimizationMetaNames.get()``

        :type meta_props: dict

        :param retention: how many job days job meta should be retained,
            takes integer values >= -1, supported only on Cloud
        :type retention: int, optional

        :param transaction_id: transaction ID to be passed with the payload
        :type transaction_id: str, optional

        :return: metadata of the created async deployment job
        :rtype: dict or str

        .. note::

            * The valid payloads for scoring input are either list of values, pandas or numpy dataframes.

        **Example:**

        .. code-block:: python

            scoring_payload = {
                client.deployments.ScoringMetaNames.INPUT_DATA: [
                    {
                        "fields": ["GENDER", "AGE", "MARITAL_STATUS", "PROFESSION"],
                        "values": [
                            ["M", 23, "Single", "Student"],
                            ["M", 55, "Single", "Executive"],
                        ],
                    }
                ]
            }
            async_job = client.deployments.create_job(
                deployment_id, scoring_payload
            )

        """
        ...
    
    async def acreate_job(self, deployment_id: str, meta_props: dict, retention: int | None = ..., transaction_id: str | None = ..., _asset_id: str | None = ...) -> str | dict:
        """Create an asynchronous deployment job asynchronously.

        :param deployment_id: unique ID of the deployment
        :type deployment_id: str

        :param meta_props: meta props. To see the available list of metanames,
            use ``client.deployments.ScoringMetaNames.get()``
            or ``client.deployments.DecisionOptimizationMetaNames.get()``

        :type meta_props: dict

        :param retention: how many job days job meta should be retained,
            takes integer values >= -1, supported only on Cloud
        :type retention: int, optional

        :param transaction_id: transaction ID to be passed with the payload
        :type transaction_id: str, optional

        :return: metadata of the created async deployment job
        :rtype: dict or str

        .. note::

            * The valid payloads for scoring input are either list of values, pandas or numpy dataframes.

        **Example:**

        .. code-block:: python

            scoring_payload = {
                client.deployments.ScoringMetaNames.INPUT_DATA: [
                    {
                        "fields": ["GENDER", "AGE", "MARITAL_STATUS", "PROFESSION"],
                        "values": [
                            ["M", 23, "Single", "Student"],
                            ["M", 55, "Single", "Executive"],
                        ],
                    }
                ]
            }
            async_job = await client.deployments.acreate_job(
                deployment_id, scoring_payload
            )

        """
        ...
    
    def get_job_details(self, job_id: str | None = ..., include: str | None = ..., limit: int | None = ..., **kwargs: Any) -> dict:
        """Get information about deployment job(s).
        If deployment job_id is not passed, all deployment jobs details are returned.

        :param job_id: unique ID of the job
        :type job_id: str, optional

        :param include: fields to be retrieved from 'decision_optimization'
            and 'scoring' section mentioned as value(s) (comma separated) as output response fields
        :type include: str, optional

        :param limit: limit number of fetched records
        :type limit: int, optional

        :return: metadata of deployment job(s)
        :rtype: dict (if job_id is not None) or {"resources": [dict]} (if job_id is None)

        **Example:**

        .. code-block:: python

            deployment_details = client.deployments.get_job_details()
            deployments_details = client.deployments.get_job_details(job_id=job_id)

        """
        ...
    
    async def aget_job_details(self, job_id: str | None = ..., include: str | None = ..., limit: int | None = ...) -> dict:
        """Get information about deployment job(s) asynchronously.
        If deployment job_id is not passed, all deployment jobs details are returned.

        :param job_id: unique ID of the job
        :type job_id: str, optional

        :param include: fields to be retrieved from 'decision_optimization'
            and 'scoring' section mentioned as value(s) (comma separated) as output response fields
        :type include: str, optional

        :param limit: limit number of fetched records
        :type limit: int, optional

        :return: metadata of deployment job(s)
        :rtype: dict (if job_id is not None) or {"resources": [dict]} (if job_id is None)

        **Example:**

        .. code-block:: python

            deployment_details = await client.deployments.aget_job_details()
            deployments_details = await client.deployments.aget_job_details(
                job_id=job_id
            )

        """
        ...
    
    def get_job_status(self, job_id: str) -> dict:
        """Get the status of a deployment job.

        :param job_id: unique ID of the deployment job
        :type job_id: str

        :return: status of the deployment job
        :rtype: dict

        **Example:**

        .. code-block:: python

            job_status = client.deployments.get_job_status(job_id)

        """
        ...
    
    async def aget_job_status(self, job_id: str) -> dict:
        """Get the status of a deployment job asynchronously.

        :param job_id: unique ID of the deployment job
        :type job_id: str

        :return: status of the deployment job
        :rtype: dict

        **Example:**

        .. code-block:: python

            job_status = await client.deployments.aget_job_status(job_id)

        """
        ...
    
    def get_job_id(self, job_details: dict) -> str:
        """Get the unique ID of a deployment job.

        :param job_details: metadata of the deployment job
        :type job_details: dict

        :return: unique ID of the deployment job
        :rtype: str

        **Example:**

        .. code-block:: python

            job_details = client.deployments.get_job_details(job_id=job_id)
            job_status = client.deployments.get_job_id(job_details)

        """
        ...
    
    def get_job_uid(self, job_details: dict) -> str:
        """Get the unique ID of a deployment job.

        *Deprecated:* Use ``get_job_id(job_details)`` instead.

        :param job_details: metadata of the deployment job
        :type job_details: dict

        :return: unique ID of the deployment job
        :rtype: str

        **Example:**

        .. code-block:: python

            job_details = client.deployments.get_job_details(job_uid=job_uid)
            job_status = client.deployments.get_job_uid(job_details)

        """
        ...
    
    def get_job_href(self, job_details: dict) -> str:
        """Get the href of a deployment job.

        :param job_details: metadata of the deployment job
        :type job_details: dict

        :return: href of the deployment job
        :rtype: str

        **Example:**

        .. code-block:: python

            job_details = client.deployments.get_job_details(job_id=job_id)
            job_status = client.deployments.get_job_href(job_details)

        """
        ...
    
    def delete_job(self, job_id: str | None = ..., hard_delete: bool = ..., **kwargs: Any) -> str:
        """Delete a deployment job that is running. This method can also delete metadata
        details of completed or canceled jobs when hard_delete parameter is set to True.

        :param job_id: unique ID of the deployment job to be deleted
        :type job_id: str

        :param hard_delete: specify `True` or `False`:

            `True` - To delete the completed or canceled job.

            `False` - To cancel the currently running deployment job.

        :type hard_delete: bool, optional

        :return: status "SUCCESS" if deletion is successful
        :rtype: Literal["SUCCESS"]
        :raises: ApiRequestFailure if deletion failed

        **Example:**

        .. code-block:: python

            client.deployments.delete_job(job_id)

        """
        ...
    
    async def adelete_job(self, job_id: str, hard_delete: bool = ...) -> str:
        """Delete a deployment job that is running asynchronously. This method can also delete metadata
        details of completed or canceled jobs when hard_delete parameter is set to True.

        :param job_id: unique ID of the deployment job to be deleted
        :type job_id: str

        :param hard_delete: specify `True` or `False`:

            `True` - To delete the completed or canceled job.

            `False` - To cancel the currently running deployment job.

        :type hard_delete: bool, optional


        :return: status "SUCCESS" if deletion is successful
        :rtype: Literal["SUCCESS"]
        :raises: ApiRequestFailure if deletion failed

        **Example:**

        .. code-block:: python

            await client.deployments.adelete_job(job_id)

        """
        ...
    
    def generate(self, deployment_id: str, prompt: str | None = ..., params: dict | None = ..., guardrails: bool = ..., guardrails_hap_params: dict | None = ..., guardrails_pii_params: dict | None = ..., concurrency_limit: int = ..., async_mode: bool = ..., validate_prompt_variables: bool = ..., guardrails_granite_guardian_params: dict | None = ...) -> dict:
        """Generate a raw response with `prompt` for given `deployment_id`.

        :param deployment_id: unique ID of the deployment
        :type deployment_id: str

        :param prompt: prompt needed for text generation. If deployment_id points to the Prompt Template asset, then the prompt argument must be None, defaults to None
        :type prompt: str, optional

        :param params: meta props for text generation, use ``ibm_watsonx_ai.metanames.GenTextParamsMetaNames().show()`` to view the list of MetaNames
        :type params: dict, optional

        :param guardrails: If True, then potentially hateful, abusive, and/or profane language (HAP) was detected
                           filter is toggle on for both prompt and generated text, defaults to False
        :type guardrails: bool, optional

        :param guardrails_hap_params: meta props for HAP moderations, use ``ibm_watsonx_ai.metanames.GenTextModerationsMetaNames().show()``
                                      to view the list of MetaNames
        :type guardrails_hap_params: dict, optional

        :param concurrency_limit: number of requests to be sent in parallel, maximum is 10
        :type concurrency_limit: int, optional

        :param async_mode: If True, then yield results asynchronously (using generator). In this case both the prompt and
                           the generated text will be concatenated in the final response - under `generated_text`, defaults
                           to False
        :type async_mode: bool, optional

        :param validate_prompt_variables: If True, prompt variables provided in `params` are validated with the ones in Prompt Template Asset.
                                          This parameter is only applicable in a Prompt Template Asset deployment scenario and should not be changed for different cases, defaults to True
        :type validate_prompt_variables: bool

        :param guardrails_granite_guardian_params: parameters for Granite Guardian moderations
        :type guardrails_granite_guardian_params: dict, optional

        :return: scoring result containing generated content
        :rtype: dict
        """
        ...
    
    async def agenerate(self, deployment_id: str, prompt: str | None = ..., params: dict | None = ..., guardrails: bool = ..., guardrails_hap_params: dict | None = ..., guardrails_pii_params: dict | None = ..., validate_prompt_variables: bool = ..., guardrails_granite_guardian_params: dict | None = ...) -> dict:
        """Generate a raw response with `prompt` for given `deployment_id` asynchronously.

        :param deployment_id: unique ID of the deployment
        :type deployment_id: str

        :param prompt: prompt needed for text generation. If deployment_id points to the Prompt Template asset, then the prompt argument must be None, defaults to None
        :type prompt: str, optional

        :param params: meta props for text generation, use ``ibm_watsonx_ai.metanames.GenTextParamsMetaNames().show()`` to view the list of MetaNames
        :type params: dict, optional

        :param guardrails: If True, then potentially hateful, abusive, and/or profane language (HAP) was detected
                           filter is toggle on for both prompt and generated text, defaults to False
        :type guardrails: bool, optional

        :param guardrails_hap_params: meta props for HAP moderations, use ``ibm_watsonx_ai.metanames.GenTextModerationsMetaNames().show()``
                                      to view the list of MetaNames
        :type guardrails_hap_params: dict, optional

        :param validate_prompt_variables: If True, prompt variables provided in `params` are validated with the ones in Prompt Template Asset.
                                          This parameter is only applicable in a Prompt Template Asset deployment scenario and should not be changed for different cases, defaults to True
        :type validate_prompt_variables: bool

        :param guardrails_granite_guardian_params: parameters for Granite Guardian moderations
        :type guardrails_granite_guardian_params: dict, optional

        :return: scoring result containing generated content
        :rtype: dict
        """
        ...
    
    async def agenerate_stream(self, deployment_id: str, prompt: str | None = ..., params: dict | None = ..., guardrails: bool = ..., guardrails_hap_params: dict | None = ..., guardrails_pii_params: dict | None = ..., validate_prompt_variables: bool = ..., guardrails_granite_guardian_params: dict | None = ...) -> AsyncGenerator:
        """Generate a raw response with `prompt` for given `deployment_id`.

        :param deployment_id: unique ID of the deployment
        :type deployment_id: str

        :param prompt: prompt needed for text generation. If deployment_id points to the Prompt Template asset, then the prompt argument must be None, defaults to None
        :type prompt: str, optional

        :param params: meta props for text generation, use ``ibm_watsonx_ai.metanames.GenTextParamsMetaNames().show()`` to view the list of MetaNames
        :type params: dict, optional

        :param guardrails: If True, then potentially hateful, abusive, and/or profane language (HAP) was detected
                           filter is toggle on for both prompt and generated text, defaults to False
        :type guardrails: bool, optional

        :param guardrails_hap_params: meta props for HAP moderations, use ``ibm_watsonx_ai.metanames.GenTextModerationsMetaNames().show()``
                                      to view the list of MetaNames
        :type guardrails_hap_params: dict, optional

        :param validate_prompt_variables: If True, prompt variables provided in `params` are validated with the ones in Prompt Template Asset.
                                          This parameter is only applicable in a Prompt Template Asset deployment scenario and should not be changed for different cases, defaults to True
        :type validate_prompt_variables: bool

        :param guardrails_granite_guardian_params: parameters for Granite Guardian moderations
        :type guardrails_granite_guardian_params: dict, optional

        :return: scoring result containing generated content
        :rtype: dict
        """
        ...
    
    def generate_text(self, deployment_id: str, prompt: str | None = ..., params: dict | None = ..., raw_response: bool = ..., guardrails: bool = ..., guardrails_hap_params: dict | None = ..., guardrails_pii_params: dict | None = ..., concurrency_limit: int = ..., validate_prompt_variables: bool = ..., guardrails_granite_guardian_params: dict | None = ...) -> str:
        """Given the selected deployment (deployment_id), a text prompt as input, and the parameters and concurrency_limit,
        the selected inference will generate a completion text as generated_text response.

        :param deployment_id: unique ID of the deployment
        :type deployment_id: str

        :param prompt: the prompt string or list of strings. If the list of strings is passed, requests will be managed in parallel with the rate of concurency_limit, defaults to None
        :type prompt: str, optional

        :param params: meta props for text generation, use ``ibm_watsonx_ai.metanames.GenTextParamsMetaNames().show()`` to view the list of MetaNames
        :type params: dict, optional

        :param raw_response: returns the whole response object
        :type raw_response: bool, optional

        :param guardrails: If True, then potentially hateful, abusive, and/or profane language (HAP) was detected
                           filter is toggle on for both prompt and generated text, defaults to False
        :type guardrails: bool, optional

        :param guardrails_hap_params: meta props for HAP moderations, use ``ibm_watsonx_ai.metanames.GenTextModerationsMetaNames().show()``
                                      to view the list of MetaNames
        :type guardrails_hap_params: dict, optional

        :param concurrency_limit: number of requests to be sent in parallel, maximum is 10
        :type concurrency_limit: int, optional

        :param validate_prompt_variables: If True, prompt variables provided in `params` are validated with the ones in Prompt Template Asset.
                                          This parameter is only applicable in a Prompt Template Asset deployment scenario and should not be changed for different cases, defaults to True
        :type validate_prompt_variables: bool

        :param guardrails_granite_guardian_params: parameters for Granite Guardian moderations
        :type guardrails_granite_guardian_params: dict, optional

        :return: generated content
        :rtype: str

        .. note::
            By default only the first occurance of `HAPDetectionWarning` is displayed. To enable printing all warnings of this category, use:

            .. code-block:: python

                import warnings
                from ibm_watsonx_ai.foundation_models.utils import HAPDetectionWarning

                warnings.filterwarnings("always", category=HAPDetectionWarning)

        """
        ...
    
    def generate_text_stream(self, deployment_id: str, prompt: str | None = ..., params: dict | None = ..., raw_response: bool = ..., guardrails: bool = ..., guardrails_hap_params: dict | None = ..., guardrails_pii_params: dict | None = ..., validate_prompt_variables: bool = ..., guardrails_granite_guardian_params: dict | None = ...) -> Generator:
        """Given the selected deployment (deployment_id), a text prompt as input and parameters,
        the selected inference will generate a streamed text as generate_text_stream.

        :param deployment_id: unique ID of the deployment
        :type deployment_id: str

        :param prompt: the prompt string, defaults to None
        :type prompt: str, optional

        :param params: meta props for text generation, use ``ibm_watsonx_ai.metanames.GenTextParamsMetaNames().show()`` to view the list of MetaNames
        :type params: dict, optional

        :param raw_response: yields the whole response object
        :type raw_response: bool, optional

        :param guardrails: If True, then potentially hateful, abusive, and/or profane language (HAP) was detected
                           filter is toggle on for both prompt and generated text, defaults to False
        :type guardrails: bool, optional

        :param guardrails_hap_params: meta props for HAP moderations, use ``ibm_watsonx_ai.metanames.GenTextModerationsMetaNames().show()``
                                      to view the list of MetaNames
        :type guardrails_hap_params: dict, optional

        :param validate_prompt_variables: If True, prompt variables provided in `params` are validated with the ones in Prompt Template Asset.
                                          This parameter is only applicable in a Prompt Template Asset deployment scenario and should not be changed for different cases, defaults to True
        :type validate_prompt_variables: bool

        :param guardrails_granite_guardian_params: parameters for Granite Guardian moderations
        :type guardrails_granite_guardian_params: dict, optional

        :return: generated content
        :rtype: str

        .. note::
            By default only the first occurance of `HAPDetectionWarning` is displayed. To enable printing all warnings of this category, use:

            .. code-block:: python

                import warnings
                from ibm_watsonx_ai.foundation_models.utils import HAPDetectionWarning

                warnings.filterwarnings("always", category=HAPDetectionWarning)

        """
        ...
    
    def chat(self, deployment_id: str, messages: ListType[dict], context: str | None = ..., tools: list | None = ..., tool_choice: dict | None = ..., tool_choice_option: Literal["none", "auto"] | None = ..., params: dict | TextChatParameters | None = ...) -> dict:
        ...
    
    def chat_stream(self, deployment_id: str, messages: ListType[dict], context: str | None = ..., tools: list | None = ..., tool_choice: dict | None = ..., tool_choice_option: Literal["none", "auto"] | None = ..., params: dict | TextChatParameters | None = ...) -> Generator:
        ...
    
    async def achat(self, deployment_id: str, messages: ListType[dict], context: str | None = ..., tools: list | None = ..., tool_choice: dict | None = ..., tool_choice_option: Literal["none", "auto"] | None = ..., params: dict | TextChatParameters | None = ...) -> dict:
        ...
    
    async def achat_stream(self, deployment_id: str, messages: ListType[dict], context: str | None = ..., tools: list | None = ..., tool_choice: dict | None = ..., tool_choice_option: Literal["none", "auto"] | None = ..., params: dict | TextChatParameters | None = ...) -> AsyncGenerator:
        ...
    
    def run_ai_service(self, deployment_id: str, ai_service_payload: dict, path_suffix: str | None = ...) -> Any:
        """Execute an AI service by providing a scoring payload.

        :param deployment_id: unique ID of the deployment
        :type deployment_id: str

        :param ai_service_payload: AI service payload to be passed to generate the method
        :type ai_service_payload: dict

        :param path_suffix: path suffix to be appended to the scoring url, defaults to None
        :type path_suffix: str, optional

        :return: response of the AI service
        :rtype: Any

        .. note::
            * By executing this class method, a POST request is performed.
            * In case of `method not allowed` error, try sending requests directly to your deployed ai service.
        """
        ...
    
    async def arun_ai_service(self, deployment_id: str, ai_service_payload: dict, path_suffix: str | None = ...) -> Any:
        """Execute an AI service by providing a scoring payload asynchronously.

        :param deployment_id: unique ID of the deployment
        :type deployment_id: str

        :param ai_service_payload: AI service payload to be passed to generate the method
        :type ai_service_payload: dict

        :param path_suffix: path suffix to be appended to the scoring url, defaults to None
        :type path_suffix: str, optional

        :return: response of the AI service
        :rtype: Any

        .. note::
            * By executing this class method, a POST request is performed.
            * In case of `method not allowed` error, try sending requests directly to your deployed ai service.
        """
        ...
    
    def run_ai_service_stream(self, deployment_id: str, ai_service_payload: dict) -> Generator:
        """Execute an AI service by providing a scoring payload.

        :param deployment_id: unique ID of the deployment
        :type deployment_id: str

        :param ai_service_payload: AI service payload to be passed to generate the method
        :type ai_service_payload: dict

        :return: stream of the response of the AI service
        :rtype: Generator
        """
        ...
    
    async def arun_ai_service_stream(self, deployment_id: str, ai_service_payload: dict) -> AsyncGenerator:
        """Execute an AI service by providing a scoring payload asynchronously.

        :param deployment_id: unique ID of the deployment
        :type deployment_id: str

        :param ai_service_payload: AI service payload to be passed to generate the method
        :type ai_service_payload: dict

        :return: stream of the response of the AI service
        :rtype: Generator
        """
        ...
    


class RuntimeContext:
    """
    Class included to keep the interface compatible with the Deployment's RuntimeContext
    used in AIServices implementation.

    :param api_client: initialized APIClient object with a set project ID or space ID. If passed, ``credentials`` and ``project_id``/``space_id`` are not required.
    :type api_client: APIClient

    :param request_payload_json: Request payload for testing of generate/ generate_stream call of AI Service.
    :type request_payload_json: dict, optional

    :param method: HTTP request method for testing of generate/ generate_stream call of AI Service.
    :type method: str, optional

    :param path: Request endpoint path for testing of generate/ generate_stream call of AI Service.
    :type path: str, optional

    ``
    RuntimeContext`` initialized for testing purposes before deployment:

    .. code-block:: python

        context = RuntimeContext(
            api_client=client, request_payload_json={"field": "value"}
        )

    Examples of ``RuntimeContext`` usage within AI Service source code:


    .. code-block:: python

        def deployable_ai_service(context, **custom):
            task_token = context.generate_token()

            def generate(context) -> dict:
                user_token = context.get_token()
                headers = context.get_headers()
                json_body = context.get_json()
                ...
                return {"body": json_body}

            return generate


        generate = deployable_ai_service(context)
        generate_output = generate(context)
        # Result:
        # {"body": {"field": "value"}}


    Change the JSON body in ``RuntimeContext``:

    .. code-block:: python

        context.request_payload_json = {"field2": "value2"}

        generate = deployable_ai_service(context)
        generate_output = generate(context)
        # Result:
        # {"body": {"field2": "value2"}}
    """
    def __init__(self, api_client: APIClient, request_payload_json: dict | None = ..., method: str | None = ..., path: str | None = ...) -> None:
        ...
    
    @property
    def request_payload_json(self) -> dict | None:
        ...
    
    @request_payload_json.setter
    def request_payload_json(self, value: dict | None) -> None:
        ...
    
    def get_token(self) -> str:
        """Return user token."""
        ...
    
    def generate_token(self) -> str:
        """Return refreshed token."""
        ...
    
    def get_headers(self) -> dict:
        """Return headers with refreshed token."""
        ...
    
    def get_json(self) -> dict | None:
        """Get payload JSON send in body of API request to the generate or generate_stream method in deployed AIService.
        For testing purposes the payload JSON need to be set in RuntimeContext initialization
        or later as request_payload_json property.
        """
        ...
    
    def get_space_id(self) -> str:
        """Return default space id."""
        ...
    
    def get_method(self) -> str:
        """Return the HTTP request method: 'GET', 'POST', etc."""
        ...
    
    def get_path_suffix(self) -> str:
        """Return the suffix of ai_service endpoint including the query parameters."""
        ...
    
    def get_query_parameters(self) -> dict:
        """Return the query parameters from the ai_service endpoint as a dict."""
        ...
    
    def get_bytes(self) -> bytes:
        """Return the request data as bytes."""
        ...
    


