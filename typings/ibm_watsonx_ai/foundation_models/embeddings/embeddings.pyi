"""
This type stub file was generated by pyright.
"""

from pathlib import Path
from typing import TYPE_CHECKING, TypeAlias
from ibm_watsonx_ai.wml_resource import WMLResource
from .base_embeddings import BaseEmbeddings
from ibm_watsonx_ai import APIClient, Credentials

if TYPE_CHECKING:
    ...
ParamsType: TypeAlias = dict[str, str | dict[str, str]]
PayloadType: TypeAlias = dict[str, str | list[str] | ParamsType]
__all__ = ["Embeddings"]
MAX_INPUTS_LENGTH = ...
DEFAULT_CONCURRENCY_LIMIT = ...
EMBEDDINGS_HTTPX_TIMEOUT = ...
_RETRY_STATUS_CODES = ...
class Embeddings(BaseEmbeddings, WMLResource):
    """Instantiate the embeddings service.

    :param model_id: the type of model to use
    :type model_id: str, optional

    :param params: parameters to use during generate requests, use ``ibm_watsonx_ai.metanames.EmbedTextParamsMetaNames().show()`` to view the list of MetaNames
    :type params: dict, optional

    :param credentials: credentials for the Watson Machine Learning instance
    :type credentials: dict, optional

    :param project_id: ID of the Watson Studio project
    :type project_id: str, optional

    :param space_id: ID of the Watson Studio space
    :type space_id: str, optional

    :param api_client: initialized APIClient object with a set project ID or space ID. If passed, ``credentials`` and ``project_id``/``space_id`` are not required.
    :type api_client: APIClient, optional

    :param verify: You can pass one of following as verify:

        * the path to a CA_BUNDLE file
        * the path of a directory with certificates of trusted CAs
        * `True` - default path to truststore will be taken
        * `False` - no verification will be made
    :type verify: bool | str | Path, optional

    :param persistent_connection: defines whether to keep a persistent connection when evaluating the `generate`, 'embed_query', and 'embed_documents` methods with one prompt
                                  or batch of prompts that meet the length limit. For more details, see `Generate embeddings <https://cloud.ibm.com/apidocs/watsonx-ai#text-embeddings>`_.
                                  To close the connection, run `embeddings.close_persistent_connection()`, defaults to True. Added in 1.1.2.
    :type persistent_connection: bool, optional

    :param batch_size: Number of elements to be embedded sending in one call (used only for sync methods), defaults to 1000
    :type batch_size: int, optional

    :param concurrency_limit: number of requests to be sent in parallel when generating embedding vectors (used only for sync methods), max is 10, defaults to 5
    :type concurrency_limit: int, optional

    :param max_retries: number of retries performed when request was not successful and status code is in retry_status_codes, defaults to 10
    :type max_retries: int, optional

    :param delay_time: delay time to retry request, factor in exponential backoff formula: wx_delay_time * pow(2.0, attempt), defaults to 0.5s
    :type delay_time: float, optional

    :param retry_status_codes: list of status codes which will be considered for retry mechanism, defaults to [429, 503, 504, 520]
    :type retry_status_codes: list[int], optional


    .. note::
        When the ``credentials`` parameter is passed, one of these parameters is required: [``project_id``, ``space_id``].

    .. hint::
        You can copy the project_id from the Project's Manage tab (Project -> Manage -> General -> Details).

    **Example:**

    .. code-block:: python

        from ibm_watsonx_ai import Credentials
        from ibm_watsonx_ai.foundation_models import Embeddings
        from ibm_watsonx_ai.metanames import EmbedTextParamsMetaNames as EmbedParams
        from ibm_watsonx_ai.foundation_models.utils.enums import EmbeddingTypes

       embed_params = {
            EmbedParams.TRUNCATE_INPUT_TOKENS: 3,
            EmbedParams.RETURN_OPTIONS: {
            'input_text': True
            }
        }

        embedding = Embeddings(
            model_id=EmbeddingTypes.IBM_SLATE_30M_ENG,
            params=embed_params,
            credentials=Credentials(
                api_key = IAM_API_KEY,
                url = "https://us-south.ml.cloud.ibm.com"),
            project_id="*****"
            )

    """
    def __init__(self, *, model_id: str, params: ParamsType | None = ..., credentials: Credentials | dict[str, str] | None = ..., project_id: str | None = ..., space_id: str | None = ..., api_client: APIClient | None = ..., verify: bool | str | Path | None = ..., persistent_connection: bool = ..., batch_size: int = ..., concurrency_limit: int = ..., max_retries: int | None = ..., delay_time: float | None = ..., retry_status_codes: list[int] | None = ...) -> None:
        ...
    
    def generate(self, inputs: list[str], params: ParamsType | None = ..., concurrency_limit: int = ...) -> dict:
        """Generate embeddings vectors for the given input with the given
        parameters. Returns a REST API response.

        :param inputs: list of texts for which embedding vectors will be generated
        :type inputs: list[str]
        :param params: MetaProps for the embedding generation, use ``ibm_watsonx_ai.metanames.EmbedTextParamsMetaNames().show()`` to view the list of MetaNames, defaults to None
        :type params: ParamsType | None, optional
        :param concurrency_limit: number of requests to be sent in parallel, max is 10, defaults to 5
        :type concurrency_limit: int, optional
        :return: scoring results containing generated embeddings vectors
        :rtype: dict
        """
        ...
    
    async def agenerate(self, inputs: list[str], params: ParamsType | None = ...) -> dict:
        """Generate embeddings vectors for the given input with the given
        parameters in an asynchronous manner. Returns a REST API response.

        :param inputs: list of texts for which embedding vectors will be generated, max length is determined by API (for more information, please refer to the documentation: https://cloud.ibm.com/apidocs/watsonx-ai#text-embeddings)
        :type inputs: list[str]
        :param params: MetaProps for the embedding generation, use ``ibm_watsonx_ai.metanames.EmbedTextParamsMetaNames().show()`` to view the list of MetaNames, defaults to None
        :type params: ParamsType | None, optional

        :return: scoring results containing generated embeddings vectors
        :rtype: dict
        """
        ...
    
    def embed_documents(self, texts: list[str], params: ParamsType | None = ..., concurrency_limit: int = ...) -> list[list[float]]:
        """Returns list of embedding vectors for provided texts.

        :param texts: list of texts for which embedding vectors will be generated
        :type texts: list[str]
        :param params: MetaProps for the embedding generation, use ``ibm_watsonx_ai.metanames.EmbedTextParamsMetaNames().show()`` to view the list of MetaNames, defaults to None
        :type params: ParamsType | None, optional
        :param concurrency_limit: number of requests to be sent in parallel, max is 10, defaults to 5
        :type concurrency_limit: int, optional

        :return: list of embedding vectors
        :rtype: list[list[float]]

        **Example:**

        .. code-block:: python

            q = [
                "What is a Generative AI?",
                "Generative AI refers to a type of artificial intelligence that can original content.",
            ]

            embedding_vectors = embedding.embed_documents(texts=q)
            print(embedding_vectors)
        """
        ...
    
    async def aembed_documents(self, texts: list[str], params: ParamsType | None = ...) -> list[list[float]]:
        """Returns list of embedding vectors for provided texts in an asynchronous manner.

        :param texts: list of texts for which embedding vectors will be generated, max length is determined by API (for more information, please refer to the documentation: https://cloud.ibm.com/apidocs/watsonx-ai#text-embeddings)
        :type texts: list[str]
        :param params: MetaProps for the embedding generation, use ``ibm_watsonx_ai.metanames.EmbedTextParamsMetaNames().show()`` to view the list of MetaNames, defaults to None
        :type params: ParamsType | None, optional

        :return: list of embedding vectors
        :rtype: list[list[float]]

        **Example:**

        .. code-block:: python

            q = [
                "What is a Generative AI?",
                "Generative AI refers to a type of artificial intelligence that can original content.",
            ]

            embedding_vectors = await embedding.aembed_documents(texts=q)
            print(embedding_vectors)
        """
        ...
    
    def embed_query(self, text: str, params: ParamsType | None = ...) -> list[float]:
        """Returns an embedding vector for a provided text.

        :param text: text for which embedding vector will be generated
        :type text: str
        :param params: MetaProps for the embedding generation, use ``ibm_watsonx_ai.metanames.EmbedTextParamsMetaNames().show()`` to view the list of MetaNames, defaults to None
        :type params: ParamsType | None, optional
        :return: embedding vector
        :rtype: list[float]

        **Example:**

        .. code-block:: python

            q = "What is a Generative AI?"
            embedding_vector = embedding.embed_query(text=q)
            print(embedding_vector)
        """
        ...
    
    async def aembed_query(self, text: str, params: ParamsType | None = ...) -> list[float]:
        """Returns an embedding vector for a provided text in an asynchronous manner.

        :param text: text for which embedding vector will be generated
        :type text: str
        :param params: MetaProps for the embedding generation, use ``ibm_watsonx_ai.metanames.EmbedTextParamsMetaNames().show()`` to view the list of MetaNames, defaults to None
        :type params: ParamsType | None, optional
        :return: embedding vector
        :rtype: list[float]

        **Example:**

        .. code-block:: python

            q = "What is a Generative AI?"
            embedding_vector = await embedding.aembed_query(text=q)
            print(embedding_vector)
        """
        ...
    
    def to_dict(self) -> dict:
        ...
    
    def close_persistent_connection(self) -> None:
        """
        Only applicable if persistent_connection was set to True in Embeddings initialization.
        Calling this method closes the current `httpx.Client` and recreates a new `httpx.Client` with default values:
        timeout: httpx.Timeout(read=30 * 60, write=30 * 60, connect=10, pool=30 * 60)
        limit: httpx.Limits(max_connections=10, max_keepalive_connections=10, keepalive_expiry=HTTPX_KEEPALIVE_EXPIRY)
        """
        ...
    


