"""
This type stub file was generated by pyright.
"""

from typing import Any, Literal
from langchain_core.documents import Document
from langchain_core.vectorstores import VectorStore as LangChainVectorStore
from ibm_watsonx_ai.client import APIClient
from ibm_watsonx_ai.foundation_models.embeddings import BaseEmbeddings
from ibm_watsonx_ai.foundation_models.extensions.rag.vector_stores.base_vector_store import BaseVectorStore
from ibm_watsonx_ai.foundation_models.extensions.rag.vector_stores.vector_store_connector import VectorStoreDataSourceType

logger = ...
class VectorStore(BaseVectorStore):
    """Universal vector store client for a RAG pattern.

    Instantiates the vector store connection in the Watson Machine Learning environment and handles the necessary operations.
    The parameters given by the keyword arguments are used to instantiate the vector store client in their
    particular constructor. Those parameters might be parsed differently.

    For details, refer to the VectorStoreConnector ``get_...`` methods.

    You can utilize the custom embedding function. This function can be provided in the constructor or by the ``set_embeddings`` method.
    For available embeddings, refer to the ``ibm_watsonx_ai.foundation_models.embeddings`` module.

    :param api_client: api client is required if connecting by connection_id, defaults to None
    :type api_client: APIClient, optional

    :param connection_id: connection asset ID, defaults to None
    :type connection_id: str, optional

    :param embeddings: default embeddings to be used, defaults to None
    :type embeddings: BaseEmbeddings, optional

    :param index_name: name of the vector database index, defaults to None
    :type index_name: str, optional

    :param datasource_type: data source type to use when ``connection_id`` is not provided, keyword arguments will be used to establish connection, defaults to None
    :type datasource_type: VectorStoreDataSourceType, str, optional

    :param distance_metric: metric used for determining vector distance, defaults to None
    :type distance_metric: Literal["euclidean", "cosine"], optional

    :param langchain_vector_store: use LangChain vector store, defaults to None
    :type langchain_vector_store: VectorStore, optional

    :param document_name_field: mapping field for document name, defaults to `document_id`
    :type document_name_field: str, optional

    :param chunk_sequence_number_field: mapping field for chunk sequence number, defaults to `sequence_number`
    :type chunk_sequence_number_field: str, optional

    **Example:**

    To connect, provide the connection asset ID.
    You can use custom embeddings to add and search documents.

    .. code-block:: python

        from ibm_watsonx_ai import APIClient
        from ibm_watsonx_ai.foundation_models.extensions.rag import VectorStore
        from ibm_watsonx_ai.foundation_models.embeddings import SentenceTransformerEmbeddings

        api_client = APIClient(credentials)

         embedding = Embeddings(
                 model_id=EmbeddingTypes.IBM_SLATE_30M_ENG,
                 api_client=api_client
                 )

        vector_store = VectorStore(
                api_client,
                connection_id='***',
                index_name='my_test_index',
                embeddings=embedding
            )

        vector_store.add_documents([
            {'content': 'document one content', 'metadata':{'url':'ibm.com'}},
            {'content': 'document two content', 'metadata':{'url':'ibm.com'}}
        ])

        vector_store.search('one', k=1)

    .. note::
        Optionally, like in LangChain, it is possible to use direct credentials to connect to Elastic Cloud.
        The keyword arguments can be used as direct params to LangChain's ``ElasticsearchStore`` constructor.

    .. code-block:: python

        from ibm_watsonx_ai import APIClient
        from ibm_watsonx_ai.foundation_models.extensions.rag import VectorStore

        api_client = APIClient(credentials)

        vector_store = VectorStore(
            api_client,
            index_name="my_test_index",
            model_id=".elser_model_2_linux-x86_64",
            cloud_id="***",
            api_key=IAM_API_KEY,
        )

        vector_store.add_documents(
            [
                {
                    "content": "document one content",
                    "metadata": {"url": "ibm.com"},
                },
                {
                    "content": "document two content",
                    "metadata": {"url": "ibm.com"},
                },
            ]
        )

        vector_store.search("one", k=1)


    """
    def __init__(self, api_client: APIClient | None = ..., *, connection_id: str | None = ..., embeddings: BaseEmbeddings | None = ..., index_name: str | None = ..., datasource_type: VectorStoreDataSourceType | str | None = ..., distance_metric: Literal["euclidean", "cosine"] | None = ..., langchain_vector_store: LangChainVectorStore | None = ..., document_name_field: str = ..., chunk_sequence_number_field: str = ..., **kwargs: Any) -> None:
        ...
    
    def to_dict(self) -> dict:
        """Serialize ``VectorStore`` into a dict that allows reconstruction using the ``from_dict`` class method.

        :return: dict for the from_dict initialization
        :rtype: dict

        :raises VectorStoreSerializationError: when instance is not serializable
        """
        ...
    
    @classmethod
    def from_dict(cls, api_client: APIClient | None = ..., data: dict | None = ..., **kwargs: Any) -> VectorStore:
        """Creates ``VectorStore`` using only a primitive data type dict.

        :param api_client: initialised APIClient used in vector store constructor, defaults to None
        :type api_client: APIClient, optional

        :param data: dict in schema like the ``to_dict()`` method
        :type data: dict

        :return: reconstructed VectorStore
        :rtype: VectorStore
        """
        ...
    
    def get_client(self) -> Any:
        ...
    
    def set_embeddings(self, embedding_fn: BaseEmbeddings) -> None:
        ...
    
    async def add_documents_async(self, content: list[Any], **kwargs: Any) -> list[str]:
        ...
    
    def add_documents(self, content: list[Any], **kwargs: Any) -> list[str]:
        ...
    
    def search(self, query: str, k: int, include_scores: bool = ..., verbose: bool = ..., **kwargs: Any) -> list:
        """Searches for documents most similar to the query.

        The method is designed as a wrapper for respective LangChain VectorStores' similarity search methods.
        Therefore, additional search parameters passed in ``kwargs`` should be consistent with those methods,
        and can be found in the LangChain documentation as they may differ depending on the connection
        type: Milvus, Chroma, Elasticsearch, etc.

        :param query: text query
        :type query: str

        :param k: number of documents to retrieve
        :type k: int

        :param include_scores: whether similarity scores of found documents should be returned, defaults to False
        :type include_scores: bool

        :param verbose: whether to display a table with the found documents, defaults to False
        :type verbose: bool

        :return: list of found documents
        :rtype: list
        """
        ...
    
    def window_search(self, query: str, k: int, include_scores: bool = ..., verbose: bool = ..., window_size: int = ..., **kwargs: Any) -> list[Document]:
        ...
    
    def delete(self, ids: list[str], **kwargs: Any) -> None:
        ...
    
    def clear(self) -> None:
        ...
    
    def count(self) -> int:
        ...
    
    def as_langchain_retriever(self, **kwargs: Any) -> Any:
        ...
    


