"""
This type stub file was generated by pyright.
"""

from typing import Any, Generic, TypeVar
from ibm_watsonx_ai.foundation_models.extensions.rag.vector_stores.base_vector_store import BaseVectorStore
from ibm_watsonx_ai.utils.utils import is_lib_installed
from langchain_core.documents import Document
from langchain_core.vectorstores import VectorStore as LangChainVectorStore

if not is_lib_installed(ext := "langchain-core"):
    ...
logger = ...
T = TypeVar("T", bound=LangChainVectorStore)
DEFAULT_DOCUMENT_NAME_FIELD = ...
DEFAULT_CHUNK_SEQUENCE_NUMBER_FIELD = ...
def merge_window_into_a_document(window: list[Document]) -> Document:
    """
    Merges a list of chunks into a single document.
    If consecutive chunks have intersecting merged_text, the merged_text is merged to avoid duplications.

    :param window: ordered list of documents for merging
    :type window: list[langchain_core.documents.Document]

    :return: document that contains the merged merged_text of the window documents
    :rtype: langchain_core.documents.Document
    """
    ...

class LangChainVectorStoreAdapter(Generic[T], BaseVectorStore):
    """
    Adapter for LangChain ``VectorStore`` base class.

    :param vector_store: concrete LangChain vector store object
    :type vector_store: langchain_core.vectorstore.VectorStore

    :param document_name_field: mapping field for document name, defaults to `document_id`
    :type document_name_field: str, optional

    :param chunk_sequence_number_field: mapping field for chunk sequence number, defaults to `sequence_number`
    :type chunk_sequence_number_field: str, optional
    """
    def __init__(self, vector_store: T, document_name_field: str = ..., chunk_sequence_number_field: str = ...) -> None:
        ...
    
    def get_client(self) -> T:
        ...
    
    def add_documents(self, content: list[str] | list[dict] | list[Document], **kwargs: Any) -> list[str]:
        """
        Embed documents and add to the vectorstore.

        :param content: Documents to add to the vectorstore.
        :type content: list[str] | list[dict] | list[langchain_core.documents.Document]

        :return: List of IDs of the added texts.
        :rtype: list[str]
        """
        ...
    
    async def add_documents_async(self, content: list[str] | list[dict] | list, **kwargs: Any) -> list[str]:
        """
        Embed documents and add to the vectorstore in asynchronous manner.

        :param content: Documents to add to the vectorstore.
        :type content: list[str] | list[dict] | list[langchain_core.documents.Document]

        :return: List of IDs of the added texts.
        :rtype: list[str]
        """
        ...
    
    def search(self, query: str, k: int, include_scores: bool = ..., verbose: bool = ..., **kwargs: Any) -> list[Document] | list[tuple[Document, float]]:
        """Searches for documents most similar to the query.

        The method is designed as a wrapper for respective LangChain VectorStores' similarity search methods.
        Therefore, additional search parameters passed in ``kwargs`` should be consistent with those methods,
        and can be found in the LangChain documentation.

        :param query: text query
        :type query: str

        :param k: number of documents to retrieve
        :type k: int

        :param include_scores: whether similarity scores of found documents should be returned, defaults to False
        :type include_scores: bool

        :param verbose: whether to display a table with the found documents, defaults to False
        :type verbose: bool

        :return: list of found documents
        :rtype: list
        """
        ...
    
    def window_search(self, query: str, k: int, include_scores: bool = ..., verbose: bool = ..., window_size: int = ..., **kwargs: Any) -> list:
        """Searches for documents most similar to the query and extend a document (a chunk) to its adjacent chunks (if they exist) from the same origin document.

        The method is designed as a wrapper for respective LangChain VectorStores' similarity search methods.
        Therefore, additional search parameters passed in ``kwargs`` should be consistent with those methods,
        and can be found in the LangChain documentation.

        :param query: text query
        :type query: str

        :param k: number of documents to retrieve
        :type k: int

        :param include_scores: whether similarity scores of found documents should be returned, defaults to False
        :type include_scores: bool

        :param verbose: whether to display a table with the found documents, defaults to False
        :type verbose: bool

        :param window_size: number of chunks
        :type window_size: int, optional

        :return: list of found documents
        :rtype: list
        """
        ...
    
    def delete(self, ids: list[str], **kwargs: Any) -> None:
        """Delete by vector ID or other criteria. Sor more details see LangChain documentation
        https://python.langchain.com/api_reference/core/vectorstores/langchain_core.vectorstores.base.VectorStore.html#langchain_core.vectorstores.base.VectorStore
        """
        ...
    
    def clear(self) -> None:
        ...
    
    def count(self) -> int:
        ...
    
    def as_langchain_retriever(self, **kwargs: Any) -> Any:
        """Return Langchain VectorStoreRetriever initialized from this VectorStore."""
        ...
    


