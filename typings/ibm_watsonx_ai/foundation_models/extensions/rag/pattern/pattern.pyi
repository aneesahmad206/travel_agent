"""
This type stub file was generated by pyright.
"""

from typing import Any, Callable
from ibm_watsonx_ai import APIClient, Credentials
from ibm_watsonx_ai.foundation_models import ModelInference
from ibm_watsonx_ai.foundation_models.extensions.rag.chunker.langchain_chunker import LangChainChunker
from ibm_watsonx_ai.foundation_models.extensions.rag.retriever import BaseRetriever
from ibm_watsonx_ai.foundation_models.extensions.rag.vector_stores import VectorStore
from ibm_watsonx_ai.helpers import DataConnection
from .pattern_assets import RAGPatternFunction

class RAGPattern:
    """Class for defining, querying and deploying Retrieval-Augmented Generation (RAG) patterns."""
    QUESTION_PLACEHOLDER = ...
    DOCUMENT_PLACEHOLDER = ...
    REFERENCE_DOCUMENTS_PLACEHOLDER = ...
    def __init__(self, *, space_id: str | None = ..., project_id: str | None = ..., api_client: APIClient | None = ..., auto_store: bool | None = ..., credentials: Credentials | dict | None = ..., model: ModelInference | None = ..., prompt_id: str | None = ..., indexing_function: Callable | None = ..., inference_function: Callable | None = ..., inference_service: Callable | None = ..., indexing_function_params: dict | None = ..., inference_function_params: dict | None = ..., store_params: dict | None = ..., retriever: BaseRetriever | None = ..., vector_store: VectorStore | None = ..., chunker: LangChainChunker | None = ..., word_to_token_ratio: float = ..., input_data_references: list[DataConnection] | None = ..., **kwargs: Any) -> None:
        """Initialize the ``RAGPattern`` object.

        .. note:: If the pattern's components (``vector_store``, ``prompt_id``, ``model``) are specified, the pattern
        will use default function template for querying and deployment. If custom ``inference_function`` is
        specified, the pattern's components are not utilized.

        .. hint:: Both default function template and custom ``inference_function`` provided by user can be modified
        by changing :meth:`pretty_print`'s output.

        :param space_id: ID of the Watson Studio space
        :type space_id: str

        :param project_id: ID of the Watson Studio project
        :type project_id: str

        :param api_client: initialized APIClient object, defaults to None
        :type api_client: APIClient, optional

        :param auto_store: whether to store the ``inference_function`` in the repository upon initialization, defaults to False
        :type auto_store: bool, optional

        :param credentials: credentials to Watson Machine Learning instance, defaults to None
        :type credentials: Credentials or dict, optional

        :param model: initialized :class:`ModelInference <ibm_watsonx_ai.foundation_models.inference.model_inference.ModelInference>` object, defaults to None
        :type model: ModelInference, optional

        :param prompt_id: Initialized ID of :class:`PromptTemplate <ibm_watsonx_ai.foundation_models.prompts.prompt_template.PromptTemplate>` object stored in space.
            Required to have ``{question}`` and ``{reference_documents}`` input variables when used with default python function, defaults to None
        :type prompt_id: str, optional

        :param indexing_function: custom python function generator containing document indexing, deprecated since 1.3.26, defaults to None
        :type indexing_function: Callable, optional

        :param inference_function: custom python function generator containing RAG logic, deprecated since 1.3.26 - use ``inference_service`` instead, defaults to None
        :type inference_function: Callable, optional

        :param inference_service: custom AI-Service containing RAG logic, defaults to None
        :type inference_service: Callable, optional

        :param indexing_function_params: optional parameters passed to the ``indexing_function``, defaults to None
        :type indexing_function_params: dict, optional

        :param inference_function_params: optional parameters passed to the ``inference_function``, defaults to None
        :type inference_function_params: dict, optional

        :param store_params: properties used for storing function in the repository, to see available meta names use: ``client.repository.FunctionMetaNames.show()``, defaults to None
        :type store_params: dict, optional

        :param retriever: initialized retriever of type :class:`BaseRetriever <ibm_watsonx_ai.foundation_models.extensions.rag.retriever.base_retriever.BaseRetriever>` object, defaults to None
        :type retriever: BaseRetriever, optional

        :param vector_store: initialized :class:`VectorStore <ibm_watsonx_ai.foundation_models.extensions.rag.vector_stores.vector_store.VectorStore>` object, defaults to None
        :type vector_store: VectorStore, optional

        :param chunker: initialized chunker of type :class:`LangChainChunker <ibm_watsonx_ai.foundation_models.extensions.rag.chunker.langchain_chunker.LangChainChunker>` object, defaults to None
        :type chunker: LangChainChunker, optional

        :param word_to_token_ratio: Constant representing the average number of tokens per word in a text, used for approximating the token count, defaults to 1.5
        :type word_to_token_ratio: float, optional

        :param input_data_references: a list of DataConnection instances from which the knowledge base will be recreated inside the deployed default AI service with `chroma` type vector store, defaults to None
        :type input_data_references: list[DataConnection] | None, optional

        .. note::
            For ``inference_function`` to be populated with parameters passed at initialization the function's signature must have a default parameter called ``params`` as its last parameter.

            .. code-block:: python

                def custom_inference_function(custom_arg="value", params=None):
                    def score(payload):
                        return payload

                    return score


        **Example:**

        .. code-block:: python

            from ibm_watsonx_ai import Credentials, APIClient
            from ibm_watsonx_ai.foundation_models.extensions.rag import RAGPattern


            def custom_inference_service(context):
                task_token = context.generate_token()

                def generate(context):
                    return {"body": context.get_json()}

                return generate


            api_client = APIClient(
                credentials=Credentials(
                    api_key=IAM_API_KEY, url="https://us-south.ml.cloud.ibm.com"
                )
            )
            pattern = RAGPattern(
                space_id="<ID of the space>",
                inference_service=custom_inference_service,
                api_client=api_client,
            )

            pattern.inference_service.deploy(name="<deployment name>")

            # inference deployment
            api_client.deployments.run_ai_service(pattern.deployment_id, payload)

        .. code-block:: python

            from ibm_watsonx_ai import Credentials
            from ibm_watsonx_ai.helpers import DataConnection
            from ibm_watsonx_ai.foundation_models import ModelInference
            from ibm_watsonx_ai.foundation_models.extensions.rag import (
                RAGPattern,
                VectorStore,
            )
            from ibm_watsonx_ai.foundation_models.extensions.rag.chunker import (
                LangChainChunker,
            )

            chroma_vector_store = VectorStore(..., datasource_type="chroma")
            model = ModelInference(...)
            chunker = LangChainChunker(...)

            pattern = RAGPattern(
                space_id="<ID of the space>",
                vector_store=chroma_vector_store,
                prompt_id="<ID of the prompt template>",
                model=model,
                credentials=Credentials(
                    api_key=IAM_API_KEY, url="https://us-south.ml.cloud.ibm.com"
                ),
                chunker=chunker,
                input_data_references=[
                    Dataconnection(data_asset_id="<id to data asset>")
                ],
            )

            pattern.inference_service.pretty_print()  # inspect autogenerated inference service body

        .. code-block:: python

            from ibm_watsonx_ai import Credentials
            from ibm_watsonx_ai.foundation_models import ModelInference
            from ibm_watsonx_ai.foundation_models.extensions.rag import (
                RAGPattern,
                VectorStore,
            )

            vector_store = VectorStore(...)
            model = ModelInference(...)

            pattern = RAGPattern(
                space_id="<ID of the space>",
                vector_store=vector_store,
                prompt_id="<ID of the prompt template>",
                model=model,
                credentials=Credentials(
                    api_key=IAM_API_KEY, url="https://us-south.ml.cloud.ibm.com"
                ),
            )

        """
        ...
    
    @property
    def indexing_function(self) -> RAGPatternFunction | None:
        """Indexing function object.

        .. deprecated:: 1.3.26

        :raises WMLClientError: raise when vector_store is of type different from
                                 ibm_watsonx_ai.foundation_models.extensions.rag.VectorStore

        :return: indexing function instance
        :rtype: RAGPatternFunction | None
        """
        ...
    
    @property
    def inference_function(self) -> RAGPatternFunction | None:
        """Inference function object.

        .. deprecated:: 1.3.26
            Use ``RAGPattern.inference_service`` instead.

        :raises WMLClientError: raise when vector_store is of type different from
                                 ibm_watsonx_ai.foundation_models.extensions.rag.VectorStore

        :return: inference function instance
        :rtype: RAGPatternFunction | None
        """
        ...
    
    def deploy(self, name: str, space_id: str | None = ..., store_params: dict | None = ..., deploy_params: dict | None = ...) -> dict:
        """Store and deploy ``inference_function`` to the space.

        .. deprecated:: 1.2.0
               `RAGPattern.deploy(...)` method is deprecated, please use "RAGPattern.inference_function.deploy(...)" instead

        :param name: Name for the stored function object as well as the deployed function. Can be overwritten by ``store_params`` and ``deploy_params``.
        :type name: str

        :param space_id: ID of the space to deploy ``inference_function`` to. Must be provided if ``space_id`` was not set at initialization.
        :type space_id: str, optional

        :param store_params: properties used for storing function in the repository, to see available meta names use: ``client.repository.FunctionMetaNames.show()``, defaults to None
        :type store_params: dict, optional

        :param deploy_params: properties used for deploying function to the space, to see available meta names use: ``client.deployments.ConfigurationMetaNames.show()``, defaults to None
        :type deploy_params: dict, optional

        :raises InvalidValue: If `inference_function` is not specified when initializing RAGPattern with custom inference objects

        :return: details of the deployed python function
        :rtype: dict

        **Example:**

        .. code-block:: python

            pattern.deploy(name="Example deployment name")

        .. code-block:: python

            deployment_details = pattern.deploy(
                name="Example deployment name",
                store_params={"software_spec_id": "<ID of the custom sw spec>"},
                deploy_params={
                    "description": "Optional deployed function description"
                },
            )

        """
        ...
    
    def query(self, payload: dict) -> dict:
        """Query the python function locally, without deploying.

        .. deprecated:: 1.2.0
               `RAGPattern.query(...)` method is deprecated, please use "RAGPattern.inference_function(...)" instead

        :param payload: payload for the scoring function
        :type payload: dict

        :raises InvalidValue: If `inference_function` is not specified when initializing RAGPattern with custom inference objects

        :return: result of the scoring function
        :rtype: dict

        **Example:**

        .. code-block:: python

            payload = {
                client.deployments.ScoringMetaNames.INPUT_DATA: [
                    {
                        "values": ["question 1", "question 2"],
                    }
                ]
            }
            result = pattern.query(payload)

        """
        ...
    
    def delete(self, delete_stored_function: bool = ...) -> None:
        """Delete stored functions object and/or deployed function from space.

        .. deprecated:: 1.2.0
               `RAGPattern.delete(...)` method is deprecated, please use "RAGPattern.inference_function.delete(...)" instead

        :param delete_stored_function: whether to delete stored function object from the repository, defaults to True
        :type delete_stored_function: bool, optional
        """
        ...
    
    @staticmethod
    def create_custom_software_spec(client: APIClient) -> dict:
        """Create a custom software specification for RAGPattern functions deployment.

        :return: details of the custom software specification
        :rtype: dict
        """
        ...
    


