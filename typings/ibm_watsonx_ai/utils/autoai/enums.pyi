"""
This type stub file was generated by pyright.
"""

from enum import Enum, StrEnum

__all__ = ["ClassificationAlgorithms", "ClassificationAlgorithmsCP4D", "RegressionAlgorithms", "RegressionAlgorithmsCP4D", "ForecastingAlgorithms", "ForecastingAlgorithmsCP4D", "PredictionType", "RAGMetrics", "Metrics", "Transformers", "DataConnectionTypes", "RunStateTypes", "PipelineTypes", "Directions", "TShirtSize", "MetricsToDirections", "PositiveLabelClass", "VisualizationTypes", "SamplingTypes", "ImputationStrategy", "ForecastingPipelineTypes", "TimeseriesAnomalyPredictionPipelineTypes", "TimeseriesAnomalyPredictionAlgorithms", "DocumentsSamplingTypes"]
class ClassificationAlgorithms(Enum):
    """Classification algorithms that AutoAI can use for IBM Cloud."""
    EX_TREES = ...
    GB = ...
    LGBM = ...
    LR = ...
    RF = ...
    XGB = ...
    DT = ...
    SnapDT = ...
    SnapRF = ...
    SnapSVM = ...
    SnapLR = ...
    SnapBM = ...


class ClassificationAlgorithmsCP4D(Enum):
    """
    Classification algorithms that AutoAI can use for IBM Cloud Pak® for Data(CP4D).
    The SnapML estimators (SnapDT, SnapRF, SnapSVM, SnapLR) are supported
    on IBM Cloud Pak® for Data version 4.0.2 and later.
    """
    EX_TREES = ...
    GB = ...
    LGBM = ...
    LR = ...
    RF = ...
    XGB = ...
    DT = ...
    SnapDT = ...
    SnapRF = ...
    SnapSVM = ...
    SnapLR = ...
    SnapBM = ...


class BatchedClassificationAlgorithms(Enum):
    """Batched tree ensemble classification algorithms that AutoAI can use for IBM Cloud."""
    RF = ...
    EX_TREES = ...
    LGBM = ...
    XGB = ...
    SnapRF = ...
    SnapBM = ...


class RegressionAlgorithms(Enum):
    """Regression algorithms that AutoAI can use for IBM Cloud."""
    RF = ...
    RIDGE = ...
    EX_TREES = ...
    GB = ...
    LR = ...
    XGB = ...
    LGBM = ...
    DT = ...
    SnapDT = ...
    SnapRF = ...
    SnapBM = ...


class RegressionAlgorithmsCP4D(Enum):
    """
    Regression algorithms that AutoAI can use for IBM Cloud Pak® for Data(CP4D).
    The SnapML estimators (SnapDT, SnapRF, SnapBM) are supported
    on IBM Cloud Pak® for Data version 4.0.2 and later.
    """
    RF = ...
    RIDGE = ...
    EX_TREES = ...
    GB = ...
    LR = ...
    XGB = ...
    LGBM = ...
    DT = ...
    SnapDT = ...
    SnapRF = ...
    SnapBM = ...


class BatchedRegressionAlgorithms(Enum):
    """Batched tree ensemble regression algorithms that AutoAI can use for IBM Cloud."""
    RF = ...
    EX_TREES = ...
    LGBM = ...
    SnapRF = ...
    SnapBM = ...
    XGB = ...


class ForecastingAlgorithmsCP4D(Enum):
    """Forecasting algorithms that AutoAI can use for IBM Cloud."""
    LR = ...
    ENSEMBLER = ...
    ARIMA = ...
    HW = ...
    BATS = ...
    RF = ...
    SVM = ...


class ForecastingAlgorithms(Enum):
    """Forecasting algorithms that AutoAI can use for IBM watsonx.ai software with IBM Cloud Pak® for Data."""
    LR = ...
    ENSEMBLER = ...
    ARIMA = ...
    HW = ...
    BATS = ...
    RF = ...
    SVM = ...


class ForecastingPipelineTypes(Enum):
    """Forecasting pipeline types that AutoAI can use for IBM Cloud Pak® for Data(CP4D)."""
    RandomForestRegressor = ...
    ExogenousRandomForestRegressor = ...
    SVM = ...
    ExogenousSVM = ...
    LocalizedFlattenEnsembler = ...
    DifferenceFlattenEnsembler = ...
    FlattenEnsembler = ...
    ExogenousLocalizedFlattenEnsembler = ...
    ExogenousDifferenceFlattenEnsembler = ...
    ExogenousFlattenEnsembler = ...
    MT2RForecaster = ...
    ExogenousMT2RForecaster = ...
    HoltWinterAdditive = ...
    HoltWinterMultiplicative = ...
    Bats = ...
    ARIMA = ...
    ARIMAX = ...
    ARIMAX_RSAR = ...
    ARIMAX_PALR = ...
    ARIMAX_RAR = ...
    ARIMAX_DMLR = ...
    @staticmethod
    def get_exogenous(): # -> list[ForecastingPipelineTypes]:
        """Get a list of pipelines that use supporting features (exogenous pipelines).

        :return: list of pipelines using supporting features
        :rtype: list[ForecastingPipelineTypes]
        """
        ...
    
    @staticmethod
    def get_non_exogenous(): # -> list[ForecastingPipelineTypes]:
        """Get a list of pipelines that are not using supporting features (non-exogenous pipelines).

        :return: list of pipelines that do not use supporting features
        :rtype: list[ForecastingPipelineTypes]
        """
        ...
    


class TimeseriesAnomalyPredictionAlgorithms(Enum):
    """Timeseries Anomaly Prediction algorithms that AutoAI can use for IBM Cloud."""
    Forecasting = ...
    Window = ...
    Relationship = ...


class TimeseriesAnomalyPredictionPipelineTypes(Enum):
    """Timeseries Anomaly Prediction pipeline types that AutoAI can use for IBM Cloud."""
    PointwiseBoundedHoltWintersAdditive = ...
    PointwiseBoundedBATS = ...
    PointwiseBoundedBATSForceUpdate = ...
    WindowNN = ...
    WindowPCA = ...
    WindowLOF = ...


class PredictionType:
    """Supported types of learning."""
    CLASSIFICATION = ...
    BINARY = ...
    MULTICLASS = ...
    REGRESSION = ...
    FORECASTING = ...
    TIMESERIES_ANOMALY_PREDICTION = ...


class PositiveLabelClass:
    """Metrics that need positive label definition for binary classification."""
    AVERAGE_PRECISION_SCORE = ...
    F1_SCORE = ...
    PRECISION_SCORE = ...
    RECALL_SCORE = ...
    F1_SCORE_MICRO = ...
    F1_SCORE_MACRO = ...
    F1_SCORE_WEIGHTED = ...
    PRECISION_SCORE_MICRO = ...
    PRECISION_SCORE_MACRO = ...
    PRECISION_SCORE_WEIGHTED = ...
    RECALL_SCORE_MICRO = ...
    RECALL_SCORE_MACRO = ...
    RECALL_SCORE_WEIGHTED = ...


class RAGMetrics:
    """Supported types of AutoAI RAG metrics"""
    ANSWER_CORRECTNESS = ...
    CONTEXT_CORRECTNESS = ...
    FAITHFULNESS = ...
    FAITHFULNESS_JUDGE = ...
    ANSWER_CORRECTNESS_JUDGE = ...


class Metrics:
    """Supported types of classification and regression metrics in AutoAI."""
    ACCURACY_SCORE = ...
    ACCURACY_AND_DISPARATE_IMPACT_SCORE = ...
    AVERAGE_PRECISION_SCORE = ...
    F1_SCORE = ...
    LOG_LOSS = ...
    PRECISION_SCORE = ...
    RECALL_SCORE = ...
    ROC_AUC_SCORE = ...
    F1_SCORE_MICRO = ...
    F1_SCORE_MACRO = ...
    F1_SCORE_WEIGHTED = ...
    PRECISION_SCORE_MICRO = ...
    PRECISION_SCORE_MACRO = ...
    PRECISION_SCORE_WEIGHTED = ...
    RECALL_SCORE_MICRO = ...
    RECALL_SCORE_MACRO = ...
    RECALL_SCORE_WEIGHTED = ...
    EXPLAINED_VARIANCE_SCORE = ...
    MEAN_ABSOLUTE_ERROR = ...
    MEAN_SQUARED_ERROR = ...
    MEAN_SQUARED_LOG_ERROR = ...
    MEDIAN_ABSOLUTE_ERROR = ...
    ROOT_MEAN_SQUARED_ERROR = ...
    ROOT_MEAN_SQUARED_LOG_ERROR = ...
    R2_SCORE = ...
    R2_AND_DISPARATE_IMPACT_SCORE = ...


class Transformers:
    """Supported types of congito transformers names in AutoAI."""
    SQRT = ...
    LOG = ...
    ROUND = ...
    SQUARE = ...
    CBRT = ...
    SIN = ...
    COS = ...
    TAN = ...
    ABS = ...
    SIGMOID = ...
    PRODUCT = ...
    MAX = ...
    DIFF = ...
    SUM = ...
    DIVIDE = ...
    STDSCALER = ...
    MINMAXSCALER = ...
    PCA = ...
    NXOR = ...
    CUBE = ...
    FEATUREAGGLOMERATION = ...
    ISOFORESTANOMALY = ...


class DataConnectionTypes:
    """Supported types of DataConnection."""
    S3 = ...
    FS = ...
    DS = ...
    CA = ...
    CN = ...
    GH = ...


class RunStateTypes:
    """Supported types of AutoAI fit/run."""
    COMPLETED = ...
    FAILED = ...


class PipelineTypes:
    """Supported types of Pipelines."""
    LALE = ...
    SKLEARN = ...
    ONNX = ...


class Directions:
    """Possible metrics directions"""
    ASCENDING = ...
    DESCENDING = ...


class TShirtSize:
    """Possible sizes of the AutoAI POD.
    Depending on the POD size, AutoAI can support different data set sizes.

    - S - small (2vCPUs and 8GB of RAM)
    - M - Medium (4vCPUs and 16GB of RAM)
    - L - Large (8vCPUs and 32GB of RAM))
    - XL - Extra Large (16vCPUs and 64GB of RAM)
    """
    S = ...
    M = ...
    L = ...
    XL = ...


class MetricsToDirections(Enum):
    """Map of metrics directions."""
    ROC_AUC = ...
    NORMALIZED_GINI_COEFFICIENT = ...
    PRECISION = ...
    AVERAGE_PRECISION = ...
    NEG_LOG_LOSS = ...
    RECALL = ...
    ACCURACY = ...
    F1 = ...
    PRECISION_MICRO = ...
    PRECISION_MACRO = ...
    PRECISION_WEIGHTED = ...
    F1_MICRO = ...
    F1_MACRO = ...
    F1_WEIGHTED = ...
    RECALL_MICRO = ...
    RECALL_MACRO = ...
    RECALL_WEIGHTED = ...
    NEG_ROOT_MEAN_SQUARED_ERROR = ...
    EXPLAINED_VARIANCE = ...
    NEG_MEAN_ABSOLUTE_ERROR = ...
    NEG_MEAN_SQUARED_ERROR = ...
    NEG_MEAN_SQUARED_LOG_ERROR = ...
    NEG_MEDIAN_ABSOLUTE_ERROR = ...
    NEG_ROOT_MEAN_SQUARED_LOG_ERROR = ...
    R2 = ...


class VisualizationTypes:
    """Types of visualization options."""
    PDF = ...
    INPLACE = ...


class SamplingTypes:
    """Types of training data sampling."""
    FIRST_VALUES = ...
    RANDOM = ...
    STRATIFIED = ...
    LAST_VALUES = ...


class DocumentsSamplingTypes:
    """Types of training data sampling."""
    RANDOM = ...
    BENCHMARK_DRIVEN = ...


class ImputationStrategy(Enum):
    """Missing values imputation strategies."""
    MEAN = ...
    MEDIAN = ...
    MOST_FREQUENT = ...
    BEST_OF_DEFAULT_IMPUTERS = ...
    VALUE = ...
    FLATTEN_ITERATIVE = ...
    LINEAR = ...
    CUBIC = ...
    PREVIOUS = ...
    NEXT = ...
    NO_IMPUTATION = ...


class KnowledgeBaseFieldRole(StrEnum):
    """
    Field name to role mapping in AutoAI RAG knowledge base.
    """
    PRIMARY_KEY = ...
    DOCUMENT_ID = ...
    DOCUMENT_NAME = ...
    CHUNK_ID = ...
    TEXT = ...
    CHUNK_START_POSITION = ...
    CHUNK_SEQUENCE_NUMBER = ...
    DENSE_VECTOR_EMBEDDINGS = ...
    SPARSE_VECTOR_EMBEDDINGS = ...


